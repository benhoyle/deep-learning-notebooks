{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Entity Functions Added to PatentData\n",
    "\n",
    "And experimenting with new functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO : Test logging info > output\n"
     ]
    }
   ],
   "source": [
    "# Initialise logging and get it to print to notebook\n",
    "# Based on answer here - \n",
    "# https://stackoverflow.com/questions/35936086/jupyter-notebook-does-not-print-logs-to-the-output-cell\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "logger.handlers[0].stream = sys.stdout\n",
    "logger.level = logging.INFO\n",
    "logger.info(\"Test logging info > output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO : Loading Patent Corpus\n",
      "INFO : Loaded Patent Corpus with 100 documents\n"
     ]
    }
   ],
   "source": [
    "# Check for saved files\n",
    "from patentdata.corpus import USPublications\n",
    "from patentdata.models.patentcorpus import PatentCorpus\n",
    "\n",
    "filename = \"g06_100.patcorp.zip\"\n",
    "\n",
    "if os.path.isfile(filename):\n",
    "    pcorp = PatentCorpus.load(filename)\n",
    "else:\n",
    "    pubs = USPublications(\"/media/SAMSUNG1/Patent_Downloads\")\n",
    "    pcorp = PatentCorpus.init_by_classification(pubs, ['G', '06'], sample_size=100)\n",
    "    pcorp.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 documents in the corpus\n",
      "The title of the first document is: METHOD, APPARATUS AND SYSTEM FOR ANSWERING REQUESTS ON PEER-TO-PEER OVERLAY NETWORK\n"
     ]
    }
   ],
   "source": [
    "# Double check loaded corpus\n",
    "print(\"There are {0} documents in the corpus\".format(len(pcorp.documents)))\n",
    "print(\"The title of the first document is: {0}\".format(pcorp.documents[0].title))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO : Loading Patent Corpus\n",
      "INFO : Loaded Patent Corpus with 200 documents\n"
     ]
    }
   ],
   "source": [
    "# Check for saved files\n",
    "from patentdata.corpus import USGrants\n",
    "\n",
    "filename = \"g06_100_grants.patcorp.zip\"\n",
    "\n",
    "if os.path.isfile(filename):\n",
    "    pcorp2 = PatentCorpus.load(filename)\n",
    "else:\n",
    "    grants = USGrants(\"/media/SAMSUNG1/US_Grants\")\n",
    "    pcorp2 = PatentCorpus.init_by_classification(grants, ['G', '06'], sample_size=100)\n",
    "    pcorp2.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Observation:\n",
    "* Maybe add each patent document to zip file as we go along. Especially useful if sampling 1000 documents or more.\n",
    "* Still takes a minute or so to load 100 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check why above is loading with 200 documents even though there are only 100 in the zip file\n",
    "pcorp2.documents = pcorp2.documents[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 documents in the corpus\n",
      "The title of the first document is: Pistol grip for a portable terminal with an internal receptacle for a stylus\n"
     ]
    }
   ],
   "source": [
    "# Double check loaded corpus\n",
    "print(\"There are {0} documents in the corpus\".format(len(pcorp2.documents)))\n",
    "print(\"The title of the first document is: {0}\".format(pcorp2.documents[0].title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1 \n",
       "1. A detachable assembly for installing and detaching a memory module having a printed circuit board in a memory slot, the printed circuit board defining a terminal portion and a free portion arranged opposite the terminal portion, comprising:\n",
       "a plurality of metal parts disposed on the free portion of the printed circuit board.\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcorp.documents[4].claimset.get_claim(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Entity - name: detachable assembly; occurrences: [A detachable assembly]; children: []; limitations: [],\n",
       " <Entity - name: memory module; occurrences: [a memory module]; children: []; limitations: [],\n",
       " <Entity - name: printed circuit board; occurrences: [a printed circuit board, the printed circuit board, the printed circuit board]; children: []; limitations: [],\n",
       " <Entity - name: memory slot; occurrences: [a memory slot]; children: []; limitations: [],\n",
       " <Entity - name: terminal portion; occurrences: [a terminal portion, the terminal portion]; children: []; limitations: [],\n",
       " <Entity - name: free portion; occurrences: [a free portion, the free portion]; children: []; limitations: [],\n",
       " <Entity - name: plurality of metal parts; occurrences: [a plurality of metal parts]; children: []; limitations: []]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcorp.documents[4].claimset.get_claim(1).entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can model parent-child relationships we can assign reference numerals based on these. Assign numerals to things explicitly present first.  \n",
    "\n",
    "If object may not need reference numeral.  \n",
    "\n",
    "Reference numerals may be denominated based on entity number: e.g. < 10, 110, 120, etc; > 10 < 20 105, 110, 115; > 20 < 50 102, 104 etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Entities in Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': [memory module,\n",
       "  memory module,\n",
       "  memory module,\n",
       "  memory module,\n",
       "  memory module,\n",
       "  memory module,\n",
       "  memory module,\n",
       "  memory module,\n",
       "  memory module,\n",
       "  memory module,\n",
       "  memory module],\n",
       " '10': [printed circuit board,\n",
       "  printed circuit board,\n",
       "  printed circuit board,\n",
       "  printed circuit board,\n",
       "  printed circuit board,\n",
       "  printed circuit board,\n",
       "  printed circuit board,\n",
       "  printed circuit board,\n",
       "  printed circuit board,\n",
       "  printed circuit board,\n",
       "  printed circuit board,\n",
       "  printed circuit board,\n",
       "  printed circuit board,\n",
       "  printed circuit board],\n",
       " '11': [plurality of packaged integrated circuits,\n",
       "  packaged integrated circuits,\n",
       "  circuits,\n",
       "  circuits],\n",
       " '12': [module card, module card],\n",
       " '13': [terminal portion,\n",
       "  terminal portion,\n",
       "  terminal portion,\n",
       "  terminal portion,\n",
       "  terminal portion,\n",
       "  terminal portion],\n",
       " '130': [metal contact region, metal contact region],\n",
       " '131': [plurality of ground terminals,\n",
       "  ground terminal,\n",
       "  ground terminal,\n",
       "  ground terminal,\n",
       "  ground terminal,\n",
       "  ground terminal],\n",
       " '14': [free portion, free portion, free portion, free portion, free portions],\n",
       " '15': [plurality of metal traces, metal trace],\n",
       " '16': [first surface,\n",
       "  first surface,\n",
       "  first and second surface,\n",
       "  first surface,\n",
       "  first surface,\n",
       "  first surface,\n",
       "  first and second surfaces,\n",
       "  first surface],\n",
       " '16,17': [first and second surfaces],\n",
       " '161': [first corner, second corner, first corners],\n",
       " '162': [corners],\n",
       " '163': [third corner,\n",
       "  third corner,\n",
       "  corners,\n",
       "  third corners,\n",
       "  third corners,\n",
       "  third corner],\n",
       " '164': [fourth corner,\n",
       "  fourth corner,\n",
       "  fourth corners,\n",
       "  fourth corners,\n",
       "  fourth corners,\n",
       "  fourth corner],\n",
       " '165': [plurality of first coupling structures,\n",
       "  first coupling structure,\n",
       "  first coupling structures,\n",
       "  first coupling structures,\n",
       "  first coupling structures],\n",
       " '17': [second surface,\n",
       "  opposing second surface,\n",
       "  second surface,\n",
       "  second surface,\n",
       "  second surface],\n",
       " '173': [third corner, third corner],\n",
       " '174': [fourth corner, fourth corner],\n",
       " '175': [plurality of second coupling structures,\n",
       "  second coupling structure,\n",
       "  second coupling structures,\n",
       "  second coupling structures,\n",
       "  second coupling structures],\n",
       " '18': [long sides, long side, long sides],\n",
       " '19': [sides, relatively short sides, sides],\n",
       " '20': [detachable assembly, detachable assembly],\n",
       " '21': [plurality of metal parts,\n",
       "  metal parts,\n",
       "  metal parts,\n",
       "  metal parts,\n",
       "  parts],\n",
       " '211B': [base wall],\n",
       " '212B': [annular side wall],\n",
       " '213B': [first retaining structure,\n",
       "  first retaining structure,\n",
       "  first retaining structure,\n",
       "  first retaining structure],\n",
       " '214B': [second retaining structure, second retaining structure],\n",
       " '21A': [foils,\n",
       "  two pairs of metal foils,\n",
       "  two pairs of metal foils,\n",
       "  metal foil,\n",
       "  metal foil,\n",
       "  metal foils,\n",
       "  foils],\n",
       " '21B': [plurality of metal sleeves,\n",
       "  two metal sleeves,\n",
       "  two metal sleeves,\n",
       "  metal sleeve,\n",
       "  metal sleeve,\n",
       "  metal sleeves,\n",
       "  metal sleeve]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcorp.documents[4].description.entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Maybe supply this data structure as an ordered dict based on int(key)... ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "ordered_entities = OrderedDict(\n",
    "        sorted(\n",
    "            pcorp.documents[4].description.entities.items(), \n",
    "            key=lambda t: int(\"\".join([n for n in t[0] if n.isnumeric()]))\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[printed circuit board,\n",
       " printed circuit board,\n",
       " printed circuit board,\n",
       " printed circuit board,\n",
       " printed circuit board,\n",
       " printed circuit board,\n",
       " printed circuit board,\n",
       " printed circuit board,\n",
       " printed circuit board,\n",
       " printed circuit board,\n",
       " printed circuit board,\n",
       " printed circuit board,\n",
       " printed circuit board,\n",
       " printed circuit board]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_entities['10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then attempt to match description and claim entities.  \n",
    "\n",
    "And develop an entity list over the complete claimset.  \n",
    "\n",
    "We have a hierarchical organisation:\n",
    "* An entity may be an abstraction of several different example entities.  \n",
    "* An entity may have one or more parts.  \n",
    "* An entity may have relationships with one or more other entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_entity_list = []\n",
    "for claim in pcorp.documents[4].claimset:\n",
    "    big_entity_list += claim.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detachable assembly\n",
      "memory module\n",
      "printed circuit board\n",
      "memory slot\n",
      "terminal portion\n",
      "free portion\n",
      "plurality of metal parts\n",
      "detachable assembly\n",
      "claim\n",
      "metal parts\n",
      "predetermined distance therebetween\n",
      "force thereon\n",
      "detachable assembly\n",
      "claim\n",
      "printed circuit board\n",
      "first surface\n",
      "oppositely arranged second surface\n",
      "first corner\n",
      "second corner\n",
      "terminal portion\n",
      "third corner\n",
      "fourth corner\n",
      "metal parts\n",
      "detachable assembly\n",
      "claim\n",
      "terminal portion\n",
      "printed circuit board\n",
      "plurality of ground terminals\n",
      "first surface\n",
      "second surfaces\n",
      "plurality of metal traces\n",
      "thereon\n",
      "end\n",
      "metal trace couples\n",
      "copper foil\n",
      "ground terminal\n",
      "detachable assembly\n",
      "claim\n",
      "metal parts\n",
      "plurality of metal sleeves\n",
      "free portion\n",
      "printed circuit board\n",
      "third corners\n",
      "first and second surfaces\n",
      "detachable assembly\n",
      "claim\n",
      "third and fourth corners\n",
      "first surface\n",
      "first coupling structure\n",
      "second coupling structure\n",
      "metal sleeves\n",
      "first retaining structure\n",
      "second retaining structure\n",
      "detachable assembly\n",
      "claim\n",
      "metal sleeves\n",
      "base wall\n",
      "annular side wall\n",
      "first retaining structure\n",
      "inner portion\n",
      "memory module\n",
      "printed circuit board\n",
      "terminal portion\n",
      "free portion\n",
      "detachable assembly\n",
      "plurality of metal parts\n",
      "memory module\n",
      "claim\n",
      "metal parts\n",
      "predetermined distance therebetween\n",
      "force thereon\n",
      "memory module\n",
      "claim\n",
      "printed circuit board\n",
      "first surface\n",
      "oppositely arranged second surface\n",
      "first corner\n",
      "second corner\n",
      "terminal portion\n",
      "third corner\n",
      "fourth corner\n",
      "metal parts\n",
      "memory module\n",
      "claim\n",
      "terminal portion\n",
      "printed circuit board\n",
      "plurality of ground terminals\n",
      "first surface\n",
      "second surfaces\n",
      "plurality of metal traces\n",
      "thereon\n",
      "end\n",
      "metal trace couples\n",
      "copper foil\n",
      "ground terminal\n",
      "memory module\n",
      "claim\n",
      "metal parts\n",
      "plurality of metal sleeves\n",
      "free portion\n",
      "printed circuit board\n",
      "third corners\n",
      "first and second surfaces\n",
      "memory module\n",
      "claim\n",
      "third and fourth corners\n",
      "first surface\n",
      "first coupling structure\n",
      "second coupling structure\n",
      "metal sleeves\n",
      "first retaining structure\n",
      "second retaining structure\n",
      "memory module\n",
      "claim\n",
      "metal sleeves\n",
      "base wall\n",
      "annular side wall\n",
      "first retaining structure\n",
      "inner portion\n"
     ]
    }
   ],
   "source": [
    "for e in big_entity_list:\n",
    "    print(e.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Observations:***\n",
    "* There are many repetitions of common entities.\n",
    "* \"claim\" occurs due to the \"according to claim X\" dependency.\n",
    "* Indexes will be based on claims rather than the claim set.\n",
    "* Can we use a similar matching algorithm to that used for the entity extraction?  \n",
    "* Probabilistically each claim is new information that can iteratively update $P(\\boldsymbol E)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Entity - name: detachable assembly; occurrences: [A detachable assembly]; children: []; limitations: []\n"
     ]
    }
   ],
   "source": [
    "print(big_entity_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['second corner', 'predetermined distance therebetween', 'inner portion', 'first and second surfaces', 'plurality of metal sleeves', 'free portion', 'copper foil', 'force thereon', 'fourth corner', 'first coupling structure', 'plurality of metal traces', 'second coupling structure', 'metal sleeves', 'third corners', 'metal trace couples', 'first corner', 'metal parts', 'third and fourth corners', 'detachable assembly', 'claim', 'oppositely arranged second surface', 'plurality of metal parts', 'base wall', 'terminal portion', 'memory module', 'memory slot', 'second surfaces', 'first surface', 'plurality of ground terminals', 'annular side wall', 'printed circuit board', 'first retaining structure', 'third corner', 'ground terminal', 'thereon', 'end', 'second retaining structure']\n"
     ]
    }
   ],
   "source": [
    " # Matching occurrences\n",
    "entity_dict = dict()\n",
    "# Now group by unique\n",
    "for entity in big_entity_list:\n",
    "    if entity.name not in entity_dict.keys():\n",
    "        entity_dict[entity.name] = list()\n",
    "    entity_dict[entity.name].append(entity)\n",
    "print(list(entity_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 119 entities extracted from the claimset; with 37 unique entities\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {0} entities extracted from the claimset; with {1} unique entities\".format(len(big_entity_list), len(list(entity_dict.keys()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'occurrences'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2477bad4cc03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         sorted(\n\u001b[1;32m      4\u001b[0m             \u001b[0mentity_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moccurrences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         )\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-28-2477bad4cc03>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      3\u001b[0m         sorted(\n\u001b[1;32m      4\u001b[0m             \u001b[0mentity_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moccurrences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         )\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'occurrences'"
     ]
    }
   ],
   "source": [
    "# Order this second dictionary by occurrence\n",
    "ordered_claimset_entities = OrderedDict(\n",
    "        sorted(\n",
    "            entity_dict.items(), \n",
    "            key=lambda t: t[1].occurrences[0][0].i \n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcorp.documents[4].claimset.claims[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at entities across claimset\n",
    "for claim in pcorp.documents[4].claimset.claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcorp.documents[4].description.get_paragraph(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcorp.documents[4].description.get_paragraph(5).sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in pcorp.documents[4].description.get_paragraph(5).sentences[0]:\n",
    "    print(word.text, word.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the spaCy pos data a reference numeral is indicated by \"NUM\" as opposed to \"CD\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entity_finder(pos_list):\n",
    "    \"\"\" Find entities with reference numerals using POS data.\"\"\"\n",
    "    entity_list = list()\n",
    "    entity = []\n",
    "    record = False\n",
    "    for i, (word, pos) in enumerate(pos_list):\n",
    "        if pos == \"DT\":\n",
    "            record = True\n",
    "            entity = []\n",
    "\n",
    "        if record:\n",
    "            entity.append((word, pos))\n",
    "\n",
    "        if \"FIG\" in word:\n",
    "            # reset entity to ignore phrases that refer to Figures\n",
    "            record = False\n",
    "            entity = []\n",
    "\n",
    "        if pos == \"CD\" and entity and record and ('NN' in pos_list[i-1][1]):\n",
    "            record = False\n",
    "            entity_list.append(entity)\n",
    "\n",
    "    return entity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.symbols import NUM, DET, NOUN\n",
    "\n",
    "def ref_num_entity_finder(doc):\n",
    "    \"\"\" Find entities with reference numerals a sentence \n",
    "    in the form of a spaCy span.\"\"\"\n",
    "    entity_list = list()\n",
    "    start_index = 0\n",
    "    record = False\n",
    "    for token in doc:\n",
    "        if token.pos == DET:\n",
    "            record = True\n",
    "            start_index = token.i\n",
    "            \n",
    "        if \"FIG\" in token.text:\n",
    "            record = False\n",
    "            \n",
    "        if token.pos == NUM and doc[token.i-1].pos == NOUN:\n",
    "             # Hack for plural nouns that may lack a determinant\n",
    "            if not record and doc[token.i-1].tag_ == \"NNS\":\n",
    "                # Follow tree for plural noun phrase\n",
    "                children = [c for c in doc[token.i-1].children]\n",
    "                if children:\n",
    "                    start_index = children[0].i\n",
    "                entity_list.append(doc[start_index:token.i+1])\n",
    "            # Add \n",
    "            if record:\n",
    "                record = False\n",
    "                entity_list.append(doc[start_index:token.i+1])\n",
    "\n",
    "    return entity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_finder(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_num_entity_finder(pcorp.documents[4].description.get_paragraph(33).sentences[1].doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in pcorp.documents[4].description.get_paragraph(33).sentences[1]:\n",
    "    print(t.text, t.i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch out each paragraph is a doc - sentences are just a span in the doc \n",
    "# - indexes are relative to the doc not the sentence\n",
    "pcorp.documents[4].description.get_paragraph(33).doc[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcorp.documents[4].description.get_paragraph(29).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This basic algorithm misses the plurals as these do not have a determinant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from patentdata.models.lib.utils import (\n",
    "    filter_entity_list\n",
    ")\n",
    "entities = list()\n",
    "for para in self.paragraphs:\n",
    "    for sentence in para.sentences:\n",
    "        e = entity_finder(\n",
    "                        [(w.text, w.tag_) for w in sentence]\n",
    "                    )\n",
    "        entities += e\n",
    "    _entities = filter_entity_list(entities)\n",
    "print(entities)\n",
    "print(_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_refnum_dict(entity_list):\n",
    "    \"\"\" Get a dictionary of reference numerals indexed by entity ngram. \"\"\"\n",
    "    ngram_list = list()\n",
    "    for entity in entity_list:\n",
    "        # Add tuple of ngram without determinant and ref num to list\n",
    "        ngram_list.append(\n",
    "            (\n",
    "                \" \".join(\n",
    "                            [\n",
    "                                word for word, pos in entity if (pos != 'DT' and pos != 'CD')\n",
    "                            ]\n",
    "                        ),\n",
    "                entity[-1][0]\n",
    "            )\n",
    "        )\n",
    "    # Sort through list and generate dictionary\n",
    "    entity_dict = dict()\n",
    "    for ngram, ref_num in ngram_list:\n",
    "        if ngram not in entity_dict.keys():\n",
    "            entity_dict[ngram] = list()\n",
    "        # Check if a variation already exists\n",
    "        exists = False\n",
    "        if ref_num not in entity_dict[ngram]:\n",
    "            entity_dict[ngram].append(ref_num)\n",
    "    return entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_refnum_dict(_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_entity_dict(entity_list):\n",
    "    \"\"\" Get a dictionary of entities indexed by reference numeral.\"\"\"\n",
    "    entity_dict = {}\n",
    "    for entity in entity_list:\n",
    "        ref_num = entity[-1][0]\n",
    "        if ref_num not in entity_dict.keys():\n",
    "            entity_dict[ref_num] = list()\n",
    "        # Check if a variation already exists\n",
    "        exists = False\n",
    "        n_gram = \" \".join([w for w, _ in entity[1:-1]])\n",
    "        for existing in entity_dict[ref_num]:\n",
    "            if n_gram == existing:\n",
    "                exists = True\n",
    "        if not exists:\n",
    "            entity_dict[ref_num].append(n_gram)\n",
    "    return entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_entity_dict(_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is picking up some plural entities in the specification. Maybe once we develop this we can implement another parse looking for string matches to dictionary entries.  \n",
    "\n",
    "Also:\n",
    "```\n",
    "'214B': ['second retaining structure'],\n",
    "'214B.': ['second retaining structure'],\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ed_from_desc = get_entity_dict(_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ed_from_desc['21B'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to adapt these functions to use the entity objects so we can store references to particular tokens rather than strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patentdata.models.lib.utils_entities import (\n",
    "    extract_entities\n",
    ")\n",
    "\n",
    "ents = extract_entities(pcorp.documents[4].description.get_paragraph(33).doc)\n",
    "print(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patentdata.models.lib.utils import nlp\n",
    "\n",
    "entities2 = list()\n",
    "entities2 = ref_num_entity_finder(nlp(pcorp.documents[4].description.text))\n",
    "print(entities2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities2[1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_entity_dict2(entity_list):\n",
    "    \"\"\" Get a dictionary of entities indexed by reference numeral.\"\"\"\n",
    "    entity_dict = {}\n",
    "    for entity in entity_list:\n",
    "        ref_num = entity[-1].text\n",
    "        # Clean fullstops\n",
    "        if ref_num[-1] == \".\":\n",
    "            ref_num = ref_num[:-1]\n",
    "        if ref_num not in entity_dict.keys():\n",
    "            entity_dict[ref_num] = list()\n",
    "        # Check if a variation already exists\n",
    "        exists = False\n",
    "        n_gram = entity[1:-1]\n",
    "        for existing in entity_dict[ref_num]:\n",
    "            if n_gram == existing:\n",
    "                exists = True\n",
    "        if not exists:\n",
    "            entity_dict[ref_num].append(n_gram)\n",
    "    return entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_entity_dict2(entities2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spacy adapted version of function\n",
    "def get_refnum_dict2(entity_list):\n",
    "    \"\"\" Get a dictionary of reference numerals indexed by entity ngram. \"\"\"\n",
    "    ngram_list = list()\n",
    "    for entity in entity_list:\n",
    "        # Add tuple of ngram without determinant and ref num to list\n",
    "        ngram_list.append(\n",
    "            (\n",
    "                \" \".join(\n",
    "                            [\n",
    "                                word.text for word in entity if (word.pos != DET and word.pos != NUM)\n",
    "                            ]\n",
    "                        ),\n",
    "                entity[-1].text\n",
    "            )\n",
    "        )\n",
    "    # Sort through list and generate dictionary\n",
    "    entity_dict = dict()\n",
    "    for ngram, ref_num in ngram_list:\n",
    "        if ngram not in entity_dict.keys():\n",
    "            entity_dict[ngram] = list()\n",
    "        # Check if a variation already exists\n",
    "        exists = False\n",
    "        if ref_num not in entity_dict[ngram]:\n",
    "            entity_dict[ngram].append(ref_num)\n",
    "    return entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_refnum_dict2(entities2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
