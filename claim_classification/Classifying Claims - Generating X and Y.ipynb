{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Claims - Generating X and Y.\n",
    "\n",
    "In this post we will look at manually converting our claim text and claim categories into a form suitable for applying deep learning algorithms. \n",
    "\n",
    "If you don't have access to the USPTO downloads you can start from here using the pickle file in the GitHub directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using USPTO data, where the claims are classified according to the International Patent Classification (IPC). To keep things simple we will use the first letter of the IPC (top level category). This is the same as the top level of the Cooperative Patent Classification (CPC).  \n",
    "\n",
    "The list of top level categories can be found here: https://rs.espacenet.com/help?locale=en_EP&method=handleHelpTopic&topic=ipc:\n",
    "* A Human Necessities\n",
    "* B Performing Operations; Transporting\n",
    "* C Chemistry; Metallurgy\n",
    "* D Textiles; Paper\n",
    "* E Fixed Constructions\n",
    "* F Mechanical Engineering; Lighting; Heating; Weapons; Blasting Engines or Pumps\n",
    "* G Physics\n",
    "* H Electricity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Machine learning algorithms generally work with numbers (typically floats of 32 or 64 bits). These numbers are arranged in multi-dimensional arrays called tensors. \n",
    "\n",
    "Most machine learning algorithms expects a training set of data to be formatted into an 'X' tensor. One dimension of this tensor represents the different training samples. Another set of dimenions then represent the data of each training sample. For example, if each claim was represented as a one-dimensional vector [3, 1, 2, ..., 3] then X might comprise a matrix where rows of the matrix represent different samples and the columns of the matrix represent different features of the sample.  \n",
    "\n",
    "For classification tasks each sample has an associated label. These are typically expected in a 'Y' tensor. Again, one dimension of this tensor represents the different training samples, while another set of dimensions represents the actual classification value for a particular sample. For example, in a simple binary case, Y may comprise a vector of 0 or 1 values. \n",
    "\n",
    "In this post we will look at how to shape numeric X and Y vectors based on our \"claim and classification\" data. In other posts we may use built in functions of machine learning libraries to do this for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's start by loading the data we saved previously in the \"Getting the Data\" post. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11238 data samples. Here is an example:\n",
      "\n",
      "('\\n1. A detector for atrial fibrillation or flutter (AF) comprising: \\nan impedance measuring unit comprising a measuring input, to which an atrial electrode line having an electrode for a unipolar measurement of an impedance in an atrium is connected and is implemented to generate an atrial impedance signal, obtained in a unipolar manner, in such a way that an impedance signal for each atrial cycle, comprising an atrial contraction and a following relaxation of said atrium, comprises multiple impedance values detected at different instants within a particular atrial cycle; \\nsaid impedance measuring unit comprising a signal input, via which a ventricle signal is to be supplied to said detector, which reflects instants of ventricular contractions in chronological assignment to said impedance signal; \\nan analysis unit configured to average multiple sequential impedance signal sections of a unipolar atrial impedance signal, which are each delimited by two sequential ventricular contractions, with one another, and to determine a maximum amplitude of an averaged unipolar atrial impedance signal section, \\nsaid analysis unit configured to compare said maximum amplitude to a comparison value, and if said maximum amplitude of said averaged unipolar atrial impedance signal is less than said comparison value, generate an AF suspicion signal. \\n\\n', 'A')\n"
     ]
    }
   ],
   "source": [
    "import pickle, os\n",
    "\n",
    "with open(\"raw_data.pkl\", \"rb\") as f:\n",
    "    raw_data = pickle.load(f)\n",
    "    \n",
    "print(\"There are {0} data samples. Here is an example:\\n\".format(len(raw_data)))\n",
    "print(raw_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenising into Words and Building a Dictionary\n",
    "\n",
    "Now we need to split our claim text into word tokens and build a dictionary of words.\n",
    "\n",
    "We will start by using NLTK word_tokenize out of the box. This breaks our long string of claim text into a list of tokens. These tokens, most of the time, should correspond to \"words\" (although occasionally errors may creep in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "data_in_words = [(word_tokenize(d[0]), d[1]) for d in raw_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1',\n",
       "  '.',\n",
       "  'A',\n",
       "  'sensing',\n",
       "  'assembly',\n",
       "  'for',\n",
       "  'sensing',\n",
       "  'a',\n",
       "  'level',\n",
       "  'of',\n",
       "  'liquid',\n",
       "  'in',\n",
       "  'a',\n",
       "  'reservoir',\n",
       "  ',',\n",
       "  'said',\n",
       "  'sensing',\n",
       "  'assembly',\n",
       "  'comprising',\n",
       "  ':',\n",
       "  'a',\n",
       "  'first',\n",
       "  'input',\n",
       "  'port',\n",
       "  'for',\n",
       "  'receiving',\n",
       "  'a',\n",
       "  'first',\n",
       "  'input',\n",
       "  'voltage',\n",
       "  'signal',\n",
       "  ';',\n",
       "  'a',\n",
       "  'second',\n",
       "  'input',\n",
       "  'port',\n",
       "  'for',\n",
       "  'receiving',\n",
       "  'a',\n",
       "  'second',\n",
       "  'input',\n",
       "  'voltage',\n",
       "  'signal',\n",
       "  ';',\n",
       "  'an',\n",
       "  'excitation',\n",
       "  'circuit',\n",
       "  'electrically',\n",
       "  'connected',\n",
       "  'to',\n",
       "  'said',\n",
       "  'first',\n",
       "  'and',\n",
       "  'second',\n",
       "  'input',\n",
       "  'ports',\n",
       "  'for',\n",
       "  'receiving',\n",
       "  'the',\n",
       "  'first',\n",
       "  'and',\n",
       "  'second',\n",
       "  'input',\n",
       "  'voltage',\n",
       "  'signals',\n",
       "  'and',\n",
       "  'for',\n",
       "  'generating',\n",
       "  'a',\n",
       "  'first',\n",
       "  'excitation',\n",
       "  'signal',\n",
       "  'and',\n",
       "  'a',\n",
       "  'second',\n",
       "  'excitation',\n",
       "  'signal',\n",
       "  ',',\n",
       "  'said',\n",
       "  'excitation',\n",
       "  'circuit',\n",
       "  'includes',\n",
       "  'first',\n",
       "  'and',\n",
       "  'second',\n",
       "  'excitation',\n",
       "  'electrodes',\n",
       "  'extending',\n",
       "  'along',\n",
       "  'a',\n",
       "  'portion',\n",
       "  'of',\n",
       "  'the',\n",
       "  'reservoir',\n",
       "  ',',\n",
       "  'said',\n",
       "  'first',\n",
       "  'and',\n",
       "  'second',\n",
       "  'excitation',\n",
       "  'electrodes',\n",
       "  'disposed',\n",
       "  'adjacent',\n",
       "  'to',\n",
       "  'and',\n",
       "  'separated',\n",
       "  'by',\n",
       "  'said',\n",
       "  'first',\n",
       "  'receiving',\n",
       "  'electrode',\n",
       "  ';',\n",
       "  'and',\n",
       "  'a',\n",
       "  'receiving',\n",
       "  'circuit',\n",
       "  'disposed',\n",
       "  'adjacent',\n",
       "  'said',\n",
       "  'excitation',\n",
       "  'circuit',\n",
       "  'defining',\n",
       "  'a',\n",
       "  'variable',\n",
       "  'capacitance',\n",
       "  'with',\n",
       "  'said',\n",
       "  'excitation',\n",
       "  'circuit',\n",
       "  ',',\n",
       "  'wherein',\n",
       "  'said',\n",
       "  'receiving',\n",
       "  'circuit',\n",
       "  'includes',\n",
       "  'first',\n",
       "  'and',\n",
       "  'second',\n",
       "  'receiving',\n",
       "  'electrodes',\n",
       "  'extending',\n",
       "  'along',\n",
       "  'a',\n",
       "  'portion',\n",
       "  'of',\n",
       "  'the',\n",
       "  'reservoir',\n",
       "  'and',\n",
       "  'a',\n",
       "  'first',\n",
       "  'trace',\n",
       "  'connected',\n",
       "  'to',\n",
       "  'ground',\n",
       "  'and',\n",
       "  'extending',\n",
       "  'between',\n",
       "  'said',\n",
       "  'first',\n",
       "  'receiving',\n",
       "  'electrode',\n",
       "  'and',\n",
       "  'said',\n",
       "  'first',\n",
       "  'and',\n",
       "  'second',\n",
       "  'excitation',\n",
       "  'electrodes',\n",
       "  ',',\n",
       "  'wherein',\n",
       "  'said',\n",
       "  'first',\n",
       "  'receiving',\n",
       "  'electrode',\n",
       "  'extends',\n",
       "  'along',\n",
       "  'a',\n",
       "  'first',\n",
       "  'non-linear',\n",
       "  'path',\n",
       "  'and',\n",
       "  'said',\n",
       "  'second',\n",
       "  'receiving',\n",
       "  'electrode',\n",
       "  'extends',\n",
       "  'along',\n",
       "  'a',\n",
       "  'second',\n",
       "  'non-linear',\n",
       "  'path',\n",
       "  'differing',\n",
       "  'from',\n",
       "  'said',\n",
       "  'first',\n",
       "  'non-linear',\n",
       "  'path',\n",
       "  ',',\n",
       "  'said',\n",
       "  'receiving',\n",
       "  'circuit',\n",
       "  'producing',\n",
       "  'an',\n",
       "  'output',\n",
       "  'voltage',\n",
       "  'signal',\n",
       "  'variable',\n",
       "  'with',\n",
       "  'the',\n",
       "  'level',\n",
       "  'of',\n",
       "  'liquid',\n",
       "  'in',\n",
       "  'the',\n",
       "  'reservoir',\n",
       "  'due',\n",
       "  'to',\n",
       "  'capacitance',\n",
       "  'changes',\n",
       "  'between',\n",
       "  'said',\n",
       "  'excitation',\n",
       "  'circuit',\n",
       "  'and',\n",
       "  'said',\n",
       "  'receiving',\n",
       "  'circuit',\n",
       "  'due',\n",
       "  'to',\n",
       "  'dielectric',\n",
       "  'changes',\n",
       "  'created',\n",
       "  'by',\n",
       "  'the',\n",
       "  'liquid',\n",
       "  '.'],\n",
       " 'G')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is an example\n",
    "data_in_words[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max claim length = 6134\n"
     ]
    }
   ],
   "source": [
    "# What is our maximum claim length?\n",
    "print(\"Max claim length = {0}\".format(max([len(d[0]) for d in data_in_words])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's long! 6134 words.   \n",
    "\n",
    "Let's have a look at how the length (in words) of our claims is distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "claim_length_counter = Counter([len(d[0]) for d in data_in_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly have a look at a histogram of the lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVIvBockqReDQ5LUy/8H/zJyb1lVkuoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f50a8f0c550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "bins = np.linspace(0, max(claim_length_counter.elements()), 200)\n",
    "plt.hist(list(claim_length_counter.elements()), bins)\n",
    "plt.title('Claim 1 - Word Length')\n",
    "plt.ylabel('No. of claims');\n",
    "plt.xlabel('Claim Word Length');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the 6134 length claim is a clear outlier. The distribution is focused around 0 to around 600 words. Let's zoom in on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLYYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f50a8f0c358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0, 600, 200)\n",
    "plt.hist(list(claim_length_counter.elements()), bins)\n",
    "plt.title('Claim 1 - Word Length')\n",
    "plt.ylabel('No. of claims');\n",
    "plt.xlabel('Claim Word Length');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applying deep learning algorithms we often need to set a maximum sequence length. When dealing with words, this is equal to the maximum number of words expected in a claim. A lower maximum sequence length will help reduce our training time. \n",
    "\n",
    "If we take all claims of less than 250 words this would still include most of the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now 10262 claims after removing long claims\n"
     ]
    }
   ],
   "source": [
    "# We might want to filter all claims over 250 tokens long\n",
    "filtered_data = [d for d in data_in_words if len(d[0]) <= 250]\n",
    "print(\"There are now {0} claims after removing long claims\".format(len(filtered_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's clear some memory\n",
    "del data_in_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now let's have a look at the words themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the words in our claims\n",
    "word_counter = Counter(sum([d[0] for d in filtered_data], list()))\n",
    "print(\"There are {0} different tokens in our dataset.\\n\".format(len(word_counter)))\n",
    "print(\"The 100 most common words are:\", word_counter.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The 100 least common words are:\", word_counter.most_common()[:-100-1:-1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save some of these to use later\n",
    "with open(\"word_counter.pkl\", \"wb\") as f:\n",
    "    pickle.dump(word_counter, f)\n",
    "with open(\"filtered_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(filtered_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function that takes our raw data and generates X and Y tensors. It is based on one provided in the Udacity Deep Learning course.\n",
    "\n",
    "First a filtering function is applied to only select claims below a certain word length. A default setting is to remove claims that have more than 250 words.\n",
    "\n",
    "The X tensor is generated by replacing each word with an integer, the integer representing an integer in a dictionary of words. A vocabulary size is passed as a parameter, which sets the maximum size of the dictionary based on the most frequent words. Words that are not in the dictionary (e.g. because they occur too infrequently) are replaced with a special UNK token.\n",
    "\n",
    "The integer value 0 is also reserved for a special PAD token. We will need this when we come to pad our data later.\n",
    "\n",
    "The Y tensor replaces each of the A to H categories with an integer value from 0 to 7.  \n",
    "\n",
    "Forward and reverse dictionaries are returned, which can be used to map to and from text to integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now bringing this all together a little\n",
    "\n",
    "def build_dataset(raw_data, length_filter=250, vocabulary_size=25000):\n",
    "    \"\"\" Convert raw data in the form of (claim_text, class) into \n",
    "    X, Y format where X is numeric data and Y is label data.\n",
    "    \n",
    "    length_filter is a parameter to filter by token length \n",
    "    (e.g. to exclude long claims).\"\"\"\n",
    "    # Tokenise and filter\n",
    "    raw_data = [(word_tokenize(d[0]), d[1]) for d in raw_data]\n",
    "    raw_data = [d for d in raw_data if len(d[0]) <= length_filter]\n",
    "    \n",
    "    # Create labels first\n",
    "    Y_text = [d[1] for d in raw_data]\n",
    "    class_dictionary = {c: i for i, c in enumerate(sorted(Counter(Y_text).keys()))} \n",
    "    Y_data = [class_dictionary[y_text] for y_text in Y_text]\n",
    "    reverse_class_dictionary = dict(zip(class_dictionary.values(), class_dictionary.keys()))\n",
    "    \n",
    "    # Create X in text\n",
    "    X_text = [d[0] for d in raw_data]\n",
    "    \n",
    "    # Change to lowercase\n",
    "    X_text = [[word.lower() for word in x_text] for x_text in X_text]\n",
    "    \n",
    "    # Create complete wordset for dictionary generation\n",
    "    words = sum(X_text, list())\n",
    "    # Reserve slots for PAD and UNK tokens\n",
    "    count = [('PAD', 0), ['UNK', -1]]\n",
    "    count.extend(Counter(words).most_common(vocabulary_size - 2))\n",
    "    \n",
    "    # Build dictionary\n",
    "    word_dictionary = {word: i for i, (word, _) in enumerate(count)}\n",
    "        \n",
    "    # Build X in indexes\n",
    "    X_data = list()\n",
    "    unk_count = 0\n",
    "    # Go through claims replacing words with index \n",
    "    for x_text in X_text:\n",
    "        x_data = list()\n",
    "        for word in x_text:\n",
    "            if word in word_dictionary:\n",
    "                index = word_dictionary[word]\n",
    "            else:\n",
    "                index = 1  # dictionary['UNK']\n",
    "                unk_count = unk_count + 1\n",
    "            x_data.append(index)\n",
    "        X_data.append(x_data)\n",
    "        \n",
    "    count[1][1] = unk_count\n",
    "    reverse_word_dictionary = dict(zip(word_dictionary.values(), word_dictionary.keys())) \n",
    "    \n",
    "    return X_data, Y_data, count, word_dictionary, reverse_word_dictionary, class_dictionary, reverse_class_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run this function on the raw data and save the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"X_Y_data.pkl\"\n",
    "\n",
    "if os.path.isfile(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        print(\"Loading data\")\n",
    "        X_data, Y_data, count, word_dictionary, reverse_word_dictionary, class_dictionary, reverse_class_dictionary = pickle.load(f)\n",
    "else:\n",
    "    X_data, Y_data, count, word_dictionary, reverse_word_dictionary, class_dictionary, reverse_class_dictionary = build_dataset(raw_data)\n",
    "    print('Most common words (+UNK)', count[:5])\n",
    "    print('Sample data', X_data[0], Y_data[0])\n",
    "    with open(filename, \"wb\") as f:\n",
    "        data = (X_data, Y_data, count, word_dictionary, reverse_word_dictionary, class_dictionary, reverse_class_dictionary)\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see our word dictionary has 25000 entries, as set by the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some examples - \"the\" is replace with the integer value 2 and \"computer\" is replaced with an integer value of 143."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dictionary[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dictionary[\"computer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see below, each claim now becomes a list of integers representing the words within the claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also have a look at our dictionary for the classification categories and some example values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_class_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check vectors are the same length\n",
    "print(len(X_data), len(Y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One issue we still have is that each sample in our X data has a different length. Most machine learning libraries need all samples to have the same length for training. To convert our X data to a series of vectors of a fixed length we can set a maximum vector size and then pad the different between the maximum vector size and our given claims.  \n",
    "\n",
    "In our function above the maximum claim length is set to 250 words. This can therefore become our maximum vector size.  \n",
    "\n",
    "Keras provides a helpful preprocessing function to provide this padding. We also need to convert our data to numpy arrays.\n",
    "\n",
    "We also split our data into training data and test data. The training data is used to train our model. The test data is used to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to split out data into training and test data - go for 80:20\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# seed for reproducing same results\n",
    "seed = 9\n",
    "np.random.seed(seed)\n",
    "\n",
    "# split the data into training (80%) and testing (20%)\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(X_data, Y_data, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we need to segment and pad our claim text sequences - we have already restricted our claims to length 250\n",
    "# We might want to experiment with changing this\n",
    "max_word_length = 250\n",
    "# Padding is performing by adding 0, which we have reserved as a PAD token above\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_word_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Our training data has length: {0} and our test data has length: {1}\".format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of our padded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_classes = len(class_dictionary)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "print(\"There are {0} classes\".format(no_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare an output vector of our deep learning models with our labels we need to convert our integer labels to what are called \"one-hot\" encodings. These are vectors with a length equal to the number of labels; an index set to 1 in the vector indicates that the label is the integer value associated with the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert labels to categorical one-hot encoding\n",
    "Y_train = to_categorical(Y_train, num_classes=no_classes)\n",
    "Y_test = to_categorical(Y_test, num_classes=no_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we now have X_train and X_test tensors in matrix form (8209/2053 samples of length 250), and Y_train and Y_test tensors in one hot-form (of size 8209/2053 by 8).  \n",
    "\n",
    "We now have everything we need to train and test some deep learning models. We will do this in another notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
