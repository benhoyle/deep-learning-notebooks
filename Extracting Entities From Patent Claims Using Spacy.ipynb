{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy Entity Extraction\n",
    "\n",
    "In this notebook we will be looking at using spaCy (https://spacy.io/) to populate object models from patent claim data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's import spaCy\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference here are some common object POS patterns as extracted from a patent specification using the reference numeral as an end point.\n",
    "```\n",
    "[('<DET><NOUN><NUM>', 63),\n",
    " ('<DET><NOUN><NOUN><NUM>', 50),\n",
    " ('<DET><VERB><NOUN><NUM>', 48),\n",
    " ('<DET><ADJ><NOUN><NUM>', 39),\n",
    " ('<DET><NOUN><NOUN><NOUN><NUM>', 35),\n",
    " ('<DET><ADJ><ADJ><NOUN><NOUN><NUM>', 14),\n",
    " ('<DET><NOUN><PUNCT><VERB><NOUN><NUM>', 8),\n",
    " ('<DET><ADJ><NOUN><NOUN><NUM>', 6),\n",
    " ('<DET><ADJ><CCONJ><ADJ><ADJ><NOUN><NOUN><NUM>', 4),\n",
    " ('<DET><NOUN><NOUN><NOUN><NOUN><NUM>', 3),\n",
    " ('<DET><NOUN><ADP><NOUN><NOUN><NUM>', 3),\n",
    " ('<DET><ADJ><CCONJ><ADJ><NOUN><NUM>', 3),\n",
    " ('<DET><NOUN><ADP><NOUN><NUM>', 3),\n",
    " ('<DET><NOUN><VERB><NOUN><NUM>', 2),\n",
    " ('<DET><NOUN><ADV><CCONJ><ADJ><NOUN><NUM>', 1),\n",
    " ('<DET><ADJ><VERB><NUM><PUNCT><NUM><ADP><VERB><NOUN><NUM>', 1),\n",
    " ('<DET><NOUN><ADP><ADV><VERB><NOUN><NUM>', 1),\n",
    " ('<DET><ADV><VERB><NOUN><NUM>', 1),\n",
    " ('<DET><ADV><VERB><VERB><NOUN><NUM>', 1),\n",
    " ('<DET><VERB><NOUN><NOUN><NUM>', 1),\n",
    " ('<DET><NOUN><PUNCT><NOUN><VERB><NOUN><NUM>', 1),\n",
    " ('<DET><NOUN><VERB><ADP><VERB><NOUN><NUM>', 1),\n",
    " ('<DET><NOUN><ADP><ADJ><ADJ><ADJ><NOUN><NOUN><NUM>', 1),\n",
    " ('<DET><ADJ><NOUN><PUNCT><NOUN><PUNCT><VERB><NOUN><NUM>', 1),\n",
    " ('<DET><PUNCT><NOUN><PUNCT><NOUN><PUNCT><VERB><NOUN><NUM>', 1),\n",
    " ('<DET><VERB><NOUN><ADV><CCONJ><ADJ><NOUN><NUM>', 1),\n",
    " ('<DET><NOUN><ADP><ADJ><NOUN><NUM>', 1)]\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some initial functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.symbols import DET, NOUN, CCONJ\n",
    "\n",
    "def simple_spacy_entity_finder(doc):\n",
    "    \"\"\" Find entities with reference numerals using POS data.\"\"\"\n",
    "    entity_list = list()\n",
    "    record = False\n",
    "    # Generate a list of tokens so we can iterate backwards through it\n",
    "    enum_doc_list = list(enumerate(doc))\n",
    "    last_end = 0\n",
    "    # Add indices\n",
    "    for i, word in enum_doc_list:\n",
    "        if word.pos == DET and not record:\n",
    "            # Start recording and record start index\n",
    "            record = True\n",
    "            start_index = i\n",
    "        else:        \n",
    "            if (word.pos == DET or word.pos == CCONJ or word.lemma_ == \";\") and record:\n",
    "                # Step back until last noun is found\n",
    "                for j, bword in reversed(enum_doc_list[last_end:i]):\n",
    "                    if bword.pos == NOUN:\n",
    "                        # Add np_chunk to buffer\n",
    "                        entity_list.append(doc[start_index:j+1])\n",
    "                        last_end = j\n",
    "                        break       \n",
    "                if word.pos == DET:\n",
    "                    # Set new start index\n",
    "                    record = True\n",
    "                    start_index = i\n",
    "                else:\n",
    "                    record = False\n",
    "    \n",
    "    entity_dict = dict()\n",
    "    # Now group by unique\n",
    "    for entity in entity_list:\n",
    "        \n",
    "        np_start = entity.start\n",
    "        # Ignore the determinant \n",
    "        if doc[np_start].pos == DET:\n",
    "            np_start += 1\n",
    "        # Generate a string representation excluding the determinant\n",
    "        np_string = doc[np_start:entity.end].text.lower()\n",
    "                                \n",
    "        if np_string not in entity_dict.keys():\n",
    "            entity_dict[np_string] = list()          \n",
    "        entity_dict[np_string].append(entity)\n",
    "    \n",
    "    return entity_list, entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.symbols import DET, NOUN\n",
    "\n",
    "def check_ant(doc, entity_dict):\n",
    "    \"\"\" Check antecedence - attempt to merge entries with incorrect antecedence.\"\"\"\n",
    "    \n",
    "    issue_keys_a = list()\n",
    "    issue_keys_the = list()\n",
    "    \n",
    "    # Look for entries with antecedence issues\n",
    "    for key in entity_dict:\n",
    "        entities = entity_dict[key]\n",
    "        # Check if first entry begins with \"a\" - flag if doesn't\n",
    "        first_entry = entities[0]\n",
    "        if first_entry[0].pos == DET and first_entry[0].lemma_ != \"a\" and first_entry[0].lemma_ != \"an\":\n",
    "            issue_keys_a.append(key)\n",
    "        \n",
    "        # If more than one entry check subsequent entries start with \"the\" - flag if don't\n",
    "        if len(entities) > 1:\n",
    "            for entity in entities[1:]:\n",
    "                if entity[0].pos == DET and entity[0].lemma_ != \"the\":\n",
    "                    issue_keys_the.append(key)\n",
    "    \n",
    "    return issue_keys_a, issue_keys_the\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def look_for_existing(doc, entity_dict):\n",
    "    \"\"\" Look for previously existing versions of problem keys.\"\"\"\n",
    "    # If more than one entry check subsequent entries start with \"the\" - flag if don't\n",
    "    issue_keys_a = list()\n",
    "    for key in entity_dict:\n",
    "        entities = entity_dict[key]\n",
    "        # Check if first entry begins with \"a\" - flag if doesn't\n",
    "        first_entry = entities[0]\n",
    "        if first_entry[0].pos == DET and first_entry[0].lemma_ != \"a\" and first_entry[0].lemma_ != \"an\":\n",
    "            issue_keys_a.append(key)\n",
    "    \n",
    "    for pkey in issue_keys_a:\n",
    "        problem_entities = entity_dict[pkey]\n",
    "        # i.e. list of two longer oblong spans\n",
    "        # Can we just work with the key initially?\n",
    "        for key in entity_dict.keys():\n",
    "            if len(pkey) > len(key) and key in pkey:\n",
    "                print(key, pkey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We now need to collate and create a set of entities\n",
    "def get_entity_set(entity_list):\n",
    "    \"\"\" Get a set of unique entity n-grams from a list of entities.\"\"\"\n",
    "    ngram_list = list()\n",
    "    for entity in entity_list:\n",
    "        ngram_list.append(\" \".join([word for word, pos in entity if (pos != 'DET')]))\n",
    "    return set(ngram_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing on Other Patent Data\n",
    "\n",
    "Lets test on different patent claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554570 records located.\n",
      "10 records sampled.\n"
     ]
    }
   ],
   "source": [
    "# Generate or create some test claim sets for analysis\n",
    "\n",
    "# (Looks like we can't pickle and load spaCy objects)\n",
    "from patentdata.corpus import USPublications\n",
    "\n",
    "pubs = USPublications(\"/media/SAMSUNG1/Patent_Downloads\")\n",
    "filegenerator = pubs.patentdoc_generator(['G', '06'], sample_size=10)\n",
    "docs = list(filegenerator)\n",
    "ent_from_claims = list()\n",
    "nlp_docs = list()\n",
    "for doc in docs:\n",
    "    nlp_doc = nlp(doc.claimset.get_claim(1).text)\n",
    "    entity_list, entity_dict = simple_spacy_entity_finder(nlp_doc)\n",
    "    nlp_docs.append(nlp_doc)\n",
    "    ent_from_claims.append(entity_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'energy collectors generate collector-local information': [the energy collectors generate collector-local information],\n",
       " 'energy park': [An energy park],\n",
       " 'information': [the information],\n",
       " 'plurality of energy collectors having known spatial location': [a plurality of energy collectors having known spatial location]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_from_claims[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These terms are not explicitly introduced using 'a/an X':\n",
      " ['information', 'energy collectors generate collector-local information'] \n",
      "\n",
      "These terms do not use 'the' yet occur previously:\n",
      " [] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ika, ikt = check_ant(nlp_docs[0], ent_from_claims[0])\n",
    "print(\"These terms are not explicitly introduced using 'a/an X':\\n\", ika, \"\\n\")\n",
    "\n",
    "print(\"These terms do not use 'the' yet occur previously:\\n\", ikt, \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "1. An energy park including a plurality of energy collectors having known spatial location where the energy collectors generate collector-local information and the information from the plurality of collectors is spatially correlated."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. An energy park including a plurality of energy collectors having known spatial location where the energy collectors generate collector-local information and the information from the plurality of collectors is spatially correlated.\n",
      " \n",
      "\n",
      "{'energy park': [An energy park], 'plurality of energy collectors having known spatial location': [a plurality of energy collectors having known spatial location], 'information': [the information], 'energy collectors generate collector-local information': [the energy collectors generate collector-local information]} \n",
      "------\n",
      "\n",
      "\n",
      "1. A method used for supporting designing of a printed circuit board including a plurality of conductive layers including conductive areas to which a constant potential is applied, comprising:\n",
      "specifying conductive areas including wiring from the conductive areas for each of the plurality of conductive layers;\n",
      "extracting areas which overlap each other from the specified conductive areas;\n",
      "specifying an interlayer connection member that electrically connects at least two of the plurality of conductive layers in the extracted area; and\n",
      "specifying an area in the extracted areas and within a predetermined distance from the specified interlayer connection member.\n",
      "\n",
      " \n",
      "\n",
      "{'printed circuit board': [a printed circuit board], '': [, ], 'method used for supporting designing': [A method used for supporting designing], 'conductive areas': [the conductive areas], 'constant potential is applied, comprising:\\nspecifying conductive areas including wiring': [a constant potential is applied, comprising:\n",
      "specifying conductive areas including wiring], 'area': [an area], 'plurality of conductive layers': [the plurality of conductive layers, the plurality of conductive layers], 'predetermined distance': [a predetermined distance], 'extracted areas': [the extracted areas], 'plurality of conductive layers including conductive areas': [a plurality of conductive layers including conductive areas], 'interlayer connection member': [an interlayer connection member], 'extracted area': [the extracted area], 'specified conductive areas': [the specified conductive areas]} \n",
      "------\n",
      "\n",
      "\n",
      "1. In recording file system information within a write-once optical disc, a file system information recording method of the write-once optical disc, comprising the step of recording file information of a former session and updated file information of a current session together within a metadata file of the current session. \n",
      " \n",
      "\n",
      "{'write-once optical disc': [a write-once optical disc, the write-once optical disc], 'step of recording file information': [the step of recording file information], 'former session': [a former session], 'metadata file': [a metadata file], 'current session': [a current session], 'file system information recording method': [a file system information recording method]} \n",
      "------\n",
      "\n",
      "\n",
      "1. A system for reselling electronic devices in compliance with second hand dealer laws, the system comprising:\n",
      "an apparatus comprising a fingerprint reader, an identification reader, an exterior imaging component, a processor, an inspection area, an imaging component within the inspection area, and an electrical connector within the inspection area, the electrical connector capable of connection to an electronic device positioned within the inspection area;\n",
      "a network;\n",
      "a server with a database, the server connected to the apparatus over the network;\n",
      "wherein the processor of the apparatus is configured to validate an identification of a recycler, process a fingerprint of the reseller to the database, photograph an image of the recycler to the database, and acquire an identification of the electronic device, the processor configured to collect as transfer data the image of the reseller, the identification information of the reseller, the fingerprint of the reseller, the identification of the electronic device, the processor configured to transmit the transfer data to the server over the network;\n",
      "wherein the server is configured to analyze the transfer data in view of a second hand dealer law for a jurisdiction of a location of the apparatus, determine a procedure for compliance of the second hand dealer law, and comply with the second hand dealer law.\n",
      "\n",
      " \n",
      "\n",
      "{'identification information': [the identification information], 'location': [a location], 'identification': [an identification, an identification, the identification], 'database': [a database, the database, the database], 'procedure for compliance': [a procedure for compliance], 'processor configured to collect as transfer data': [the processor configured to collect as transfer data], 'jurisdiction': [a jurisdiction], 'electronic device': [an electronic device, the electronic device, the electronic device], 'apparatus': [an apparatus, the apparatus, the apparatus, the apparatus], 'system': [the system], 'image': [an image, the image], 'identification reader': [an identification reader], 'transfer data': [the transfer data], 'inspection area': [an inspection area, the inspection area, the inspection area, the inspection area], 'electrical connector': [an electrical connector], 'network': [a network, the network, the network], 'processor': [a processor, the processor, the processor], 'second hand dealer law': [a second hand dealer law, the second hand dealer law], 'transfer data in view': [the transfer data in view], 'recycler, process': [a recycler, process], 'system for reselling electronic devices in compliance with second hand dealer laws': [A system for reselling electronic devices in compliance with second hand dealer laws], 'reseller': [the reseller, the reseller, the reseller, the reseller], 'exterior imaging component': [an exterior imaging component], 'fingerprint': [a fingerprint, the fingerprint], 'electrical connector capable of connection': [the electrical connector capable of connection], 'server': [a server, the server, the server, the server], 'imaging component': [an imaging component], 'fingerprint reader': [a fingerprint reader], 'recycler': [the recycler]} \n",
      "------\n",
      "\n",
      "\n",
      "1. A device, comprising:\n",
      "at least one encrypted processor that is configured to determine an input map associated with a texture pattern and calculate a reduced resolution pattern based on the input map; and\n",
      "at least one second processor, communicably connected to the at least one encrypted processor, that is configured to:\n",
      "receive the reduced resolution pattern and a plurality of similar patterns, each associated with a stored encrypted map template, and\n",
      "identify a match-set if a match exists between the reduced resolution pattern and the plurality of similar patterns,\n",
      "\n",
      "wherein the at least one encrypted processor is further configured to receive the match-set and identify if a match exists between the input map and any stored encrypted map template associated with the match-set.\n",
      "\n",
      " \n",
      "\n",
      "{'reduced resolution pattern': [a reduced resolution pattern, the reduced resolution pattern, the reduced resolution pattern], '': [, ], 'input map': [an input map, the input map, the input map], 'stored encrypted map template': [a stored encrypted map template, any stored encrypted map template], 'texture pattern': [a texture pattern], 'plurality of similar patterns': [a plurality of similar patterns, the plurality of similar patterns], 'device, comprising:\\nat least one encrypted processor': [A device, comprising:\n",
      "at least one encrypted processor], 'match': [a match, a match, a match], 'at least one encrypted processor': [the at least one encrypted processor, the at least one encrypted processor], 'match-set': [the match-set]} \n",
      "------\n",
      "\n",
      "\n",
      "1. A control device for a hybrid vehicle including an engine, a motor/generator, and at least one driving wheel, the hybrid vehicle operable in an electric drive mode in which the vehicle is powered only by the motor/generator and a hybrid drive mode in which the vehicle is powered by both the engine and the motor/generator, the control device comprising:\n",
      "a controller configured to:\n",
      "set a first threshold level of an accelerator opening;\n",
      "set a second threshold level of the accelerator opening, wherein a hysteresis value is defined between the first threshold level and the second threshold level;\n",
      "change the hysteresis value based on at least one of a vehicle operating state and a driving environment;\n",
      "receive a signal corresponding to the accelerator opening;\n",
      "initiate a changeover from the hybrid drive mode to the electric drive mode if the accelerator opening is less than the first threshold level; and\n",
      "initiate a changeover from the electric drive mode to the hybrid drive mode if the accelerator opening is greater than the second threshold value.\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "{'engine': [an engine, the engine], '': [], 'electric drive mode': [an electric drive mode, the electric drive mode, the electric drive mode], 'driving environment': [a driving environment], 'vehicle': [the vehicle, the vehicle], 'hybrid vehicle': [a hybrid vehicle, the hybrid vehicle], 'controller': [a controller], 'second threshold level': [a second threshold level, the second threshold level], 'signal': [a signal], 'changeover': [a changeover, a changeover], 'hysteresis value': [a hysteresis value, the hysteresis value], 'accelerator opening': [an accelerator opening, the accelerator opening, the accelerator opening, the accelerator opening, the accelerator opening], 'control device': [A control device, the control device], 'motor/generator': [a motor/generator, the motor/generator, the motor/generator], 'hybrid drive mode': [a hybrid drive mode, the hybrid drive mode, the hybrid drive mode], 'vehicle operating state': [a vehicle operating state], 'first threshold level': [a first threshold level, the first threshold level, the first threshold level]} \n",
      "------\n",
      "\n",
      "\n",
      "1. An information processing device, wherein a graphics plane configured to store a graphics image is a storage region where two image storage regions, which are an L (Left) region that is an image storage region to store an image for the left eye, and an R (Right) region that is an image storage region to store an image for the right eye, are disposed in an array;\n",
      "and wherein drawing of said image for the left eye used for animation as to said L region, and drawing of said image for the right eye used for animation as to said R region are individually performed.\n",
      "\n",
      " \n",
      "\n",
      "{'graphics image': [a graphics image], 'l (left) region': [an L (Left) region], 'graphics plane': [a graphics plane], 'image': [an image, an image], 'left eye': [the left eye], 'left eye used for animation as to said l region': [the left eye used for animation as to said L region], 'storage region where two image storage regions': [a storage region where two image storage regions], 'array': [an array], 'right eye': [the right eye], 'r (right) region': [an R (Right) region], 'image storage region': [an image storage region, an image storage region], 'information processing device': [An information processing device]} \n",
      "------\n",
      "\n",
      "\n",
      "1. A system for filtering data to be pushed from a server to a communication device in accordance with a set of predefined rules, the system comprising: \n",
      "(a) a personal content filter database for storing the set of predefined rules, the set of predefined rules comprising user defined rules received from an associated user via a user interface on the communication device; and \n",
      "(b) a content filter engine for implementing the set of predefined rules by preventing restricted information from being transmitted to the communication device. \n",
      "\n",
      " \n",
      "\n",
      "{'set of predefined rules by preventing restricted information': [the set of predefined rules by preventing restricted information], 'communication device': [the communication device], 'user interface': [a user interface], 'set of predefined rules comprising user defined rules': [the set of predefined rules comprising user defined rules], 'content filter engine': [a content filter engine], 'system for filtering data': [A system for filtering data], 'system': [the system], 'set of predefined rules': [a set of predefined rules, the set of predefined rules], 'communication device in accordance': [a communication device in accordance], 'server': [a server], 'personal content filter database': [a personal content filter database], 'associated user': [an associated user]} \n",
      "------\n",
      "\n",
      "\n",
      "1. A method for translating instant messages exchanged between two or more devices over a network by one or more users that communicate in different languages, the method comprising: \n",
      "establishing a user profile indicating at least one user language and one or more translation preferences of the one or more users; \n",
      "receiving a message as input composed by at least one of the users according to the user language; \n",
      "translating the message from the user language to at least one different language corresponding to the one or more translation preferences; and \n",
      "transmitting the message in translated form to at least one of the two or more devices. \n",
      "\n",
      " \n",
      "\n",
      "{'': [, , ], 'message as input': [a message as input], 'network': [a network], 'message': [the message], 'method': [the method], 'message in translated form': [the message in translated form], 'user language': [the user language], 'user language to at least one different language': [the user language to at least one different language], 'method for translating instant messages': [A method for translating instant messages], 'users': [the users], 'user profile indicating at least one user language': [a user profile indicating at least one user language]} \n",
      "------\n",
      "\n",
      "\n",
      "1. A vehicle device control system comprising:\n",
      "a portable unit carried by a user; and\n",
      "a vehicle-side unit mounted in a vehicle for performing bilateral communications with the portable unit,\n",
      "in each of the bilateral communications, the vehicle-side unit transmitting a request signal in a predetermined area around the vehicle and the portable unit transmitting a response signal in response to the request signal of the vehicle-side unit,\n",
      "the vehicle-side unit checking up an identification code included in the response signal received from the portable unit with a pre-stored registration code, and\n",
      "the vehicle-side unit controlling a vehicle device mounted in the vehicle on condition that a checkup result indicates a successful checkup operation,\n",
      "wherein the vehicle-side unit includes:\n",
      "a vehicle-side transmission section for transmitting the request signal to the portable unit;\n",
      "a vehicle-side reception section for receiving the response signal from the portable unit; and\n",
      "a vehicle-side control section for instructing the vehicle-side transmission section to transmit the request signal at a predetermined transmission interval specific to the vehicle side unit, when the response signal is received from the portable unit by the vehicle-side reception section, and\n",
      "wherein the portable unit is operable with power supply from a battery, and includes:\n",
      "a portable-side reception section for receiving the request signal from the vehicle-side unit;\n",
      "a portable-side transmission section for transmitting the response signal to the vehicle-side unit;\n",
      "a portable-side memory section for storing the transmission interval in the vehicle-side unit; and\n",
      "a portable-side control section for instructing the portable-side transmission section to transmit the response signal when the request signal is received by the portable-side reception section, and for instructing the portable-side reception section to take a reception state at a timing of next transmission of the request signal in correspondence to the transmission interval stored in the portable-side memory section.\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "{'': [], 'response signal in response': [a response signal in response], 'portable-side transmission section': [a portable-side transmission section, the portable-side transmission section], 'bilateral communications': [the bilateral communications], 'predetermined area': [a predetermined area], 'timing of next transmission': [a timing of next transmission], 'reception state': [a reception state], 'user': [a user], 'identification code': [an identification code], 'portable unit': [a portable unit, the portable unit, the portable unit, the portable unit, the portable unit, the portable unit, the portable unit], 'vehicle device': [a vehicle device], 'vehicle-side reception section': [a vehicle-side reception section, the vehicle-side reception section], 'battery': [a battery], 'checkup result': [a checkup result], 'portable-side control section': [a portable-side control section], 'response signal': [the response signal, the response signal, the response signal, the response signal, the response signal], 'portable-side reception section': [a portable-side reception section, the portable-side reception section, the portable-side reception section], 'vehicle-side control section': [a vehicle-side control section], 'successful checkup operation': [a successful checkup operation], 'request signal in correspondence': [the request signal in correspondence], 'vehicle device control system': [A vehicle device control system], 'request signal': [a request signal, the request signal, the request signal, the request signal, the request signal, the request signal], 'vehicle': [the vehicle], 'predetermined transmission interval': [a predetermined transmission interval], 'vehicle for performing bilateral communications': [a vehicle for performing bilateral communications], 'portable-side memory section': [a portable-side memory section], 'vehicle side unit': [the vehicle side unit], 'pre-stored registration code': [a pre-stored registration code], 'vehicle-side unit': [a vehicle-side unit, the vehicle-side unit, the vehicle-side unit, the vehicle-side unit, the vehicle-side unit, the vehicle-side unit, the vehicle-side unit, the vehicle-side unit, the vehicle-side unit], 'transmission interval': [the transmission interval, the transmission interval], 'portable unit is operable with power supply': [the portable unit is operable with power supply], 'vehicle on condition': [the vehicle on condition], 'vehicle-side transmission section': [a vehicle-side transmission section, the vehicle-side transmission section]} \n",
      "------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d, e in zip(nlp_docs, ent_from_claims):\n",
    "    print(d, \"\\n\")\n",
    "    print(e, \"\\n------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* Matching occurrences of \"the X\" with other entries looks generally useful (e.g. is needed across multiple claims). Phrases such as \"the given X\" or \"the selected X\" also appear.\n",
    "* There are some long sections that appear not to meet the simple parse.\n",
    "* Some have a blank entity?\n",
    "* We could use the noun_chunks as a second test and merge for greater accuracy?\n",
    "* Doesn't work so well on some method claims.\n",
    "* Need to stop on punctuation as well, i.e. \",\" or \";\"\n",
    "* \"said\" needs to be a DET.\n",
    "* Plurals cause an issue, e.g. \"multimedia data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " [An energy park, a plurality, energy collectors, known spatial location, the energy collectors, collector-local information, the information, the plurality, collectors] \n",
      "\n",
      "['energy park', 'plurality of energy collectors having known spatial location', 'information', 'energy collectors generate collector-local information']\n",
      "\n",
      "-----\n",
      "\n",
      "----\n",
      " [A method, designing, a printed circuit board, a plurality, conductive layers, conductive areas, a constant potential, conductive areas, wiring, areas, the plurality, conductive layers, areas, the specified conductive areas, an interlayer connection member, the plurality, conductive layers, the extracted area, an area, the extracted areas, a predetermined distance, the specified interlayer connection member] \n",
      "\n",
      "['printed circuit board', '', 'method used for supporting designing', 'conductive areas', 'constant potential is applied, comprising:\\nspecifying conductive areas including wiring', 'area', 'plurality of conductive layers', 'predetermined distance', 'extracted areas', 'plurality of conductive layers including conductive areas', 'interlayer connection member', 'extracted area', 'specified conductive areas']\n",
      "\n",
      "-----\n",
      "\n",
      "----\n",
      " [file system information, a write-once optical disc, the write-once optical disc, the step, file information, a former session, information, a current session, a metadata file, the current session] \n",
      "\n",
      "['write-once optical disc', 'step of recording file information', 'former session', 'metadata file', 'current session', 'file system information recording method']\n",
      "\n",
      "-----\n",
      "\n",
      "----\n",
      " [A system, electronic devices, compliance, second hand dealer laws, an apparatus, a fingerprint reader, the inspection area, the inspection area, connection, an electronic device, the inspection area, a database, the apparatus, the network, the processor, the apparatus, an identification, a recycler, process, a fingerprint, the reseller, the database, an image, the recycler, the database, an identification, the electronic device, the processor, transfer data, the image, the reseller, the reseller, the fingerprint, the reseller, the identification, the electronic device, the processor, the transfer data, the server, the network, the server, the transfer data, view, a second hand dealer law, a jurisdiction, a location, the apparatus, a procedure, compliance, the second hand dealer law, the second hand dealer law] \n",
      "\n",
      "['identification information', 'location', 'identification', 'database', 'procedure for compliance', 'processor configured to collect as transfer data', 'jurisdiction', 'electronic device', 'apparatus', 'system', 'image', 'identification reader', 'transfer data', 'inspection area', 'electrical connector', 'network', 'processor', 'second hand dealer law', 'transfer data in view', 'recycler, process', 'system for reselling electronic devices in compliance with second hand dealer laws', 'reseller', 'exterior imaging component', 'fingerprint', 'electrical connector capable of connection', 'server', 'imaging component', 'fingerprint reader', 'recycler']\n",
      "\n",
      "-----\n",
      "\n",
      "----\n",
      " [A device, at least one encrypted processor, an input map, a texture pattern, a reduced resolution pattern, the input map, at least one second processor, the at least one encrypted processor, the reduced resolution pattern, a plurality, similar patterns, a stored encrypted map template, a match, the reduced resolution pattern, the plurality, similar patterns, the at least one encrypted processor, the match-set, a match, the input map, any stored encrypted map template, the match-set] \n",
      "\n",
      "['reduced resolution pattern', '', 'input map', 'stored encrypted map template', 'texture pattern', 'plurality of similar patterns', 'device, comprising:\\nat least one encrypted processor', 'match', 'at least one encrypted processor', 'match-set']\n",
      "\n",
      "-----\n",
      "\n",
      "----\n",
      " [A control device, a hybrid vehicle, an engine, a motor/generator, wheel, the hybrid vehicle, an electric drive mode, the vehicle, the motor/generator, a hybrid drive mode, the vehicle, both the engine, the motor/generator, the control device, a controller, a first threshold level, an accelerator opening, a second threshold level, the accelerator opening, a hysteresis value, the first threshold level, the second threshold level, the hysteresis value, a vehicle operating state, a driving environment, a signal, the accelerator opening, a changeover, the hybrid drive mode, the electric drive mode, the accelerator opening, the first threshold level, a changeover, the electric drive mode, the hybrid drive mode, the accelerator opening, the second threshold value] \n",
      "\n",
      "['engine', '', 'electric drive mode', 'driving environment', 'vehicle', 'hybrid vehicle', 'controller', 'second threshold level', 'signal', 'changeover', 'hysteresis value', 'accelerator opening', 'control device', 'motor/generator', 'hybrid drive mode', 'vehicle operating state', 'first threshold level']\n",
      "\n",
      "-----\n",
      "\n",
      "----\n",
      " [An information processing device, a graphics plane, a graphics image, a storage region, two image storage regions, an L, region, an image storage region, an image, the left eye, an R, an image storage region, an image, the right eye, an array, said image, the left eye, animation, L region, drawing, said image, the right eye, animation, said R region] \n",
      "\n",
      "['graphics image', 'l (left) region', 'graphics plane', 'image', 'left eye', 'left eye used for animation as to said l region', 'storage region where two image storage regions', 'array', 'right eye', 'r (right) region', 'image storage region', 'information processing device']\n",
      "\n",
      "-----\n",
      "\n",
      "----\n",
      " [A system, data, a server, a communication device, accordance, a set, predefined rules, a personal content filter database, the set, predefined rules, the set, predefined rules, user, rules, an associated user, a user interface, the communication device, a content filter engine, the set, predefined rules, information, the communication device] \n",
      "\n",
      "['set of predefined rules by preventing restricted information', 'communication device', 'user interface', 'set of predefined rules comprising user defined rules', 'content filter engine', 'system for filtering data', 'system', 'set of predefined rules', 'communication device in accordance', 'server', 'personal content filter database', 'associated user']\n",
      "\n",
      "-----\n",
      "\n",
      "----\n",
      " [A method, instant messages, two or more devices, a network, one or more users, different languages, a user profile, at least one user language, one or more translation preferences, the one or more users, a message, input, the users, the user language, the message, the user language, at least one different language, the one or more translation preferences, the message, form, the two or more devices] \n",
      "\n",
      "['', 'message as input', 'network', 'message', 'method', 'message in translated form', 'user language', 'user language to at least one different language', 'method for translating instant messages', 'users', 'user profile indicating at least one user language']\n",
      "\n",
      "-----\n",
      "\n",
      "----\n",
      " [A vehicle device control system, a portable unit, a user, a vehicle-side unit, a vehicle, bilateral communications, the portable unit, the bilateral communications, a request signal, a predetermined area, the vehicle, the portable unit, a response signal, response, the request signal, the vehicle-side unit, the vehicle-side unit, an identification code, the response signal, the portable unit, a pre-stored registration code, the vehicle-side unit, a vehicle device, the vehicle, condition, a checkup result, a successful checkup operation, the vehicle-side unit, a vehicle-side transmission section, the request signal, the portable unit, a vehicle-side reception section, the response signal, the portable unit, a vehicle-side control section, the vehicle-side transmission section, the request signal, a predetermined transmission interval, the vehicle side unit, the response signal, the portable unit, the vehicle-side reception section, the portable unit, power supply, a battery, a portable-side reception section, the request signal, the vehicle-side unit, a portable-side transmission section, the response signal, the vehicle-side unit, a portable-side memory section, the transmission interval, the vehicle-side unit, a portable-side control section, the portable-side transmission section, the response signal, the request signal, the portable-side reception section, the portable-side reception section, a reception state, a timing, next transmission, the request signal, correspondence, the transmission interval, the portable-side memory section] \n",
      "\n",
      "['', 'response signal in response', 'portable-side transmission section', 'bilateral communications', 'predetermined area', 'timing of next transmission', 'reception state', 'user', 'identification code', 'portable unit', 'vehicle device', 'vehicle-side reception section', 'battery', 'checkup result', 'portable-side control section', 'response signal', 'portable-side reception section', 'vehicle-side control section', 'successful checkup operation', 'request signal in correspondence', 'vehicle device control system', 'request signal', 'vehicle', 'predetermined transmission interval', 'vehicle for performing bilateral communications', 'portable-side memory section', 'vehicle side unit', 'pre-stored registration code', 'vehicle-side unit', 'transmission interval', 'portable unit is operable with power supply', 'vehicle on condition', 'vehicle-side transmission section']\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d, e in zip(nlp_docs, ent_from_claims):\n",
    "    print(\"----\\n\", list(d.noun_chunks), \"\\n\")\n",
    "    print(list(e.keys()))\n",
    "    print(\"\\n-----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can I define the problem using probabilities?  \n",
    "\n",
    "Entities are latent variables of which the words are the visible / observable data.  \n",
    "\n",
    "Problem is aligning groups of tokens with entities. Classification in a case where we don't know what the classes are or how many classes there are.  \n",
    "\n",
    "P(entity | words)\n",
    "\n",
    "What do we know for certain:\n",
    "* It will have a form of DET ... NOUN or no DET but noun phrase ending in NNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def annotated_entity_extraction(doc):\n",
    "    entity_list = list()\n",
    "    record = False\n",
    "    # Generate a list of tokens so we can iterate backwards through it\n",
    "    enum_doc_list = list(enumerate(doc))\n",
    "    last_end = 0\n",
    "    # Add indices\n",
    "    for i, word in enum_doc_list:\n",
    "        print(i, word, record)\n",
    "        if word.pos == DET and not record:\n",
    "            # Start recording and record start index\n",
    "            record = True\n",
    "            start_index = i\n",
    "            print(\"Starting to record at {0}-{1}\".format(i, word))\n",
    "        else:        \n",
    "            if (word.pos == DET or word.pos == CCONJ or word.lemma_ == \";\" or word.lemma_ == '.') and record:\n",
    "                print(\"Stepping back at {0}-{1}\".format(i, word))\n",
    "                # Step back until last noun is found\n",
    "                added = False\n",
    "                for j, bword in reversed(enum_doc_list[last_end:i]):\n",
    "                    print(j, bword, last_end)\n",
    "                    if bword.pos == NOUN:\n",
    "                        # Add np_chunk to buffer\n",
    "                        print(\"-----> Adding from {0}-{1} = {2}\".format(j, i, doc[start_index:j+1]))\n",
    "                        entity_list.append(doc[start_index:j+1])\n",
    "                        last_end = j+1\n",
    "                        added = True\n",
    "                        break\n",
    "                # Here if nothing has been added, e.g. no noun found, we need to keep recording\n",
    "                if word.pos == DET:\n",
    "                    # Set new start index\n",
    "                    record = True\n",
    "                    start_index = i\n",
    "                    print(\"Starting to record again at {0}-{1}\".format(i, word))\n",
    "                else:\n",
    "                    if (word.pos == CCONJ and not added):\n",
    "                        record = True\n",
    "                    else:\n",
    "                        record = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      " False\n",
      "1 1 False\n",
      "2 . False\n",
      "3 An False\n",
      "Starting to record at 3-An\n",
      "4 energy True\n",
      "5 park True\n",
      "6 including True\n",
      "7 a True\n",
      "Stepping back at 7-a\n",
      "6 including 0\n",
      "5 park 0\n",
      "-----> Adding from 5-7 = An energy park\n",
      "Starting to record again at 7-a\n",
      "8 plurality True\n",
      "9 of True\n",
      "10 energy True\n",
      "11 collectors True\n",
      "12 having True\n",
      "13 known True\n",
      "14 spatial True\n",
      "15 location True\n",
      "16 where True\n",
      "17 the True\n",
      "Stepping back at 17-the\n",
      "16 where 6\n",
      "15 location 6\n",
      "-----> Adding from 15-17 = a plurality of energy collectors having known spatial location\n",
      "Starting to record again at 17-the\n",
      "18 energy True\n",
      "19 collectors True\n",
      "20 generate True\n",
      "21 collector True\n",
      "22 - True\n",
      "23 local True\n",
      "24 information True\n",
      "25 and True\n",
      "Stepping back at 25-and\n",
      "24 information 16\n",
      "-----> Adding from 24-25 = the energy collectors generate collector-local information\n",
      "26 the False\n",
      "Starting to record at 26-the\n",
      "27 information True\n",
      "28 from True\n",
      "29 the True\n",
      "Stepping back at 29-the\n",
      "28 from 25\n",
      "27 information 25\n",
      "-----> Adding from 27-29 = the information\n",
      "Starting to record again at 29-the\n",
      "30 plurality True\n",
      "31 of True\n",
      "32 collectors True\n",
      "33 is True\n",
      "34 spatially True\n",
      "35 correlated True\n",
      "36 . True\n",
      "Stepping back at 36-.\n",
      "35 correlated 28\n",
      "34 spatially 28\n",
      "33 is 28\n",
      "32 collectors 28\n",
      "-----> Adding from 32-36 = the plurality of collectors\n",
      "37 \n",
      " False\n"
     ]
    }
   ],
   "source": [
    "annotated_entity_extraction(nlp_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      " False\n",
      "1 1 False\n",
      "2 . False\n",
      "3 A False\n",
      "Starting to record at 3-A\n",
      "4 method True\n",
      "5 used True\n",
      "6 for True\n",
      "7 supporting True\n",
      "8 designing True\n",
      "9 of True\n",
      "10 a True\n",
      "Stepping back at 10-a\n",
      "9 of 0\n",
      "8 designing 0\n",
      "-----> Adding from 8-10 = A method used for supporting designing\n",
      "Starting to record again at 10-a\n",
      "11 printed True\n",
      "12 circuit True\n",
      "13 board True\n",
      "14 including True\n",
      "15 a True\n",
      "Stepping back at 15-a\n",
      "14 including 9\n",
      "13 board 9\n",
      "-----> Adding from 13-15 = a printed circuit board\n",
      "Starting to record again at 15-a\n",
      "16 plurality True\n",
      "17 of True\n",
      "18 conductive True\n",
      "19 layers True\n",
      "20 including True\n",
      "21 conductive True\n",
      "22 areas True\n",
      "23 to True\n",
      "24 which True\n",
      "25 a True\n",
      "Stepping back at 25-a\n",
      "24 which 14\n",
      "23 to 14\n",
      "22 areas 14\n",
      "-----> Adding from 22-25 = a plurality of conductive layers including conductive areas\n",
      "Starting to record again at 25-a\n",
      "26 constant True\n",
      "27 potential True\n",
      "28 is True\n",
      "29 applied True\n",
      "30 , True\n",
      "31 comprising True\n",
      "32 : True\n",
      "33 \n",
      " True\n",
      "34 specifying True\n",
      "35 conductive True\n",
      "36 areas True\n",
      "37 including True\n",
      "38 wiring True\n",
      "39 from True\n",
      "40 the True\n",
      "Stepping back at 40-the\n",
      "39 from 23\n",
      "38 wiring 23\n",
      "-----> Adding from 38-40 = a constant potential is applied, comprising:\n",
      "specifying conductive areas including wiring\n",
      "Starting to record again at 40-the\n",
      "41 conductive True\n",
      "42 areas True\n",
      "43 for True\n",
      "44 each True\n",
      "Stepping back at 44-each\n",
      "43 for 39\n",
      "42 areas 39\n",
      "-----> Adding from 42-44 = the conductive areas\n",
      "Starting to record again at 44-each\n",
      "45 of True\n",
      "46 the True\n",
      "Stepping back at 46-the\n",
      "45 of 43\n",
      "44 each 43\n",
      "43 for 43\n",
      "Starting to record again at 46-the\n",
      "47 plurality True\n",
      "48 of True\n",
      "49 conductive True\n",
      "50 layers True\n",
      "51 ; True\n",
      "Stepping back at 51-;\n",
      "50 layers 43\n",
      "-----> Adding from 50-51 = the plurality of conductive layers\n",
      "52 \n",
      " False\n",
      "53 extracting False\n",
      "54 areas False\n",
      "55 which False\n",
      "56 overlap False\n",
      "57 each False\n",
      "Starting to record at 57-each\n",
      "58 other True\n",
      "59 from True\n",
      "60 the True\n",
      "Stepping back at 60-the\n",
      "59 from 51\n",
      "58 other 51\n",
      "57 each 51\n",
      "56 overlap 51\n",
      "55 which 51\n",
      "54 areas 51\n",
      "-----> Adding from 54-60 = \n",
      "Starting to record again at 60-the\n",
      "61 specified True\n",
      "62 conductive True\n",
      "63 areas True\n",
      "64 ; True\n",
      "Stepping back at 64-;\n",
      "63 areas 55\n",
      "-----> Adding from 63-64 = the specified conductive areas\n",
      "65 \n",
      " False\n",
      "66 specifying False\n",
      "67 an False\n",
      "Starting to record at 67-an\n",
      "68 interlayer True\n",
      "69 connection True\n",
      "70 member True\n",
      "71 that True\n",
      "72 electrically True\n",
      "73 connects True\n",
      "74 at True\n",
      "75 least True\n",
      "76 two True\n",
      "77 of True\n",
      "78 the True\n",
      "Stepping back at 78-the\n",
      "77 of 64\n",
      "76 two 64\n",
      "75 least 64\n",
      "74 at 64\n",
      "73 connects 64\n",
      "72 electrically 64\n",
      "71 that 64\n",
      "70 member 64\n",
      "-----> Adding from 70-78 = an interlayer connection member\n",
      "Starting to record again at 78-the\n",
      "79 plurality True\n",
      "80 of True\n",
      "81 conductive True\n",
      "82 layers True\n",
      "83 in True\n",
      "84 the True\n",
      "Stepping back at 84-the\n",
      "83 in 71\n",
      "82 layers 71\n",
      "-----> Adding from 82-84 = the plurality of conductive layers\n",
      "Starting to record again at 84-the\n",
      "85 extracted True\n",
      "86 area True\n",
      "87 ; True\n",
      "Stepping back at 87-;\n",
      "86 area 83\n",
      "-----> Adding from 86-87 = the extracted area\n",
      "88 and False\n",
      "89 \n",
      " False\n",
      "90 specifying False\n",
      "91 an False\n",
      "Starting to record at 91-an\n",
      "92 area True\n",
      "93 in True\n",
      "94 the True\n",
      "Stepping back at 94-the\n",
      "93 in 87\n",
      "92 area 87\n",
      "-----> Adding from 92-94 = an area\n",
      "Starting to record again at 94-the\n",
      "95 extracted True\n",
      "96 areas True\n",
      "97 and True\n",
      "Stepping back at 97-and\n",
      "96 areas 93\n",
      "-----> Adding from 96-97 = the extracted areas\n",
      "98 within False\n",
      "99 a False\n",
      "Starting to record at 99-a\n",
      "100 predetermined True\n",
      "101 distance True\n",
      "102 from True\n",
      "103 the True\n",
      "Stepping back at 103-the\n",
      "102 from 97\n",
      "101 distance 97\n",
      "-----> Adding from 101-103 = a predetermined distance\n",
      "Starting to record again at 103-the\n",
      "104 specified True\n",
      "105 interlayer True\n",
      "106 connection True\n",
      "107 member True\n",
      "108 . True\n",
      "Stepping back at 108-.\n",
      "107 member 102\n",
      "-----> Adding from 107-108 = the specified interlayer connection member\n",
      "109 \n",
      "\n",
      " False\n"
     ]
    }
   ],
   "source": [
    "annotated_entity_extraction(nlp_docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_entity_finder(doc):\n",
    "    \"\"\" Find entities using noun phrases/chunks.\"\"\"\n",
    "    entity_dict = dict()\n",
    "    for entity in doc.noun_chunks:\n",
    "        np_start = entity.start\n",
    "        # Ignore the determinant \n",
    "        if doc[np_start].pos == DET:\n",
    "            np_start += 1\n",
    "        # Generate a string representation excluding the determinant\n",
    "        np_string = doc[np_start:entity.end].text.lower()\n",
    "                                \n",
    "        if np_string not in entity_dict.keys():\n",
    "            entity_dict[np_string] = list()          \n",
    "        entity_dict[np_string].append(entity)\n",
    "        \n",
    "    return entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'area': [an area],\n",
       " 'areas': [areas, areas],\n",
       " 'conductive areas': [conductive areas, conductive areas],\n",
       " 'conductive layers': [conductive layers,\n",
       "  conductive layers,\n",
       "  conductive layers],\n",
       " 'constant potential': [a constant potential],\n",
       " 'designing': [designing],\n",
       " 'extracted area': [the extracted area],\n",
       " 'extracted areas': [the extracted areas],\n",
       " 'interlayer connection member': [an interlayer connection member],\n",
       " 'method': [A method],\n",
       " 'plurality': [a plurality, the plurality, the plurality],\n",
       " 'predetermined distance': [a predetermined distance],\n",
       " 'printed circuit board': [a printed circuit board],\n",
       " 'specified conductive areas': [the specified conductive areas],\n",
       " 'specified interlayer connection member': [the specified interlayer connection member],\n",
       " 'wiring': [wiring]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_entity_finder(nlp_docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([A method used for supporting designing,\n",
       "  a printed circuit board,\n",
       "  a plurality of conductive layers including conductive areas,\n",
       "  a constant potential is applied, comprising:\n",
       "  specifying conductive areas including wiring,\n",
       "  the conductive areas,\n",
       "  ,\n",
       "  the plurality of conductive layers,\n",
       "  ,\n",
       "  the specified conductive areas,\n",
       "  an interlayer connection member,\n",
       "  the plurality of conductive layers,\n",
       "  the extracted area,\n",
       "  an area,\n",
       "  the extracted areas,\n",
       "  a predetermined distance],\n",
       " {'': [, ],\n",
       "  'area': [an area],\n",
       "  'conductive areas': [the conductive areas],\n",
       "  'constant potential is applied, comprising:\\nspecifying conductive areas including wiring': [a constant potential is applied, comprising:\n",
       "   specifying conductive areas including wiring],\n",
       "  'extracted area': [the extracted area],\n",
       "  'extracted areas': [the extracted areas],\n",
       "  'interlayer connection member': [an interlayer connection member],\n",
       "  'method used for supporting designing': [A method used for supporting designing],\n",
       "  'plurality of conductive layers': [the plurality of conductive layers,\n",
       "   the plurality of conductive layers],\n",
       "  'plurality of conductive layers including conductive areas': [a plurality of conductive layers including conductive areas],\n",
       "  'predetermined distance': [a predetermined distance],\n",
       "  'printed circuit board': [a printed circuit board],\n",
       "  'specified conductive areas': [the specified conductive areas]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_spacy_entity_finder(nlp_docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'current session': [a current session, the current session],\n",
       " 'file information': [file information],\n",
       " 'file system information': [file system information],\n",
       " 'former session': [a former session],\n",
       " 'information': [information],\n",
       " 'metadata file': [a metadata file],\n",
       " 'step': [the step],\n",
       " 'write-once optical disc': [a write-once optical disc,\n",
       "  the write-once optical disc]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_entity_finder(nlp_docs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([a write-once optical disc,\n",
       "  a file system information recording method,\n",
       "  the write-once optical disc,\n",
       "  the step of recording file information,\n",
       "  a former session,\n",
       "  a current session,\n",
       "  a metadata file],\n",
       " {'current session': [a current session],\n",
       "  'file system information recording method': [a file system information recording method],\n",
       "  'former session': [a former session],\n",
       "  'metadata file': [a metadata file],\n",
       "  'step of recording file information': [the step of recording file information],\n",
       "  'write-once optical disc': [a write-once optical disc,\n",
       "   the write-once optical disc]})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_spacy_entity_finder(nlp_docs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the Algorithm\n",
    "\n",
    "What do we know:\n",
    "* A DET or a NOUN will always form part of an entity.\n",
    "* A plural noun may not start with a DET.\n",
    "* An entity will consist of consecutive tokens.\n",
    "* The world following a DET will be part of the entity.\n",
    "* Each determinant can only be linked to one of the nouns in front of it before the next determinant or [\";\", \":\", \".\"] (and possibly \",\").\n",
    "* Entities with a \"the\" determinant should have occurred before.\n",
    "* There are no overlaps.\n",
    "* We can be more confident if a phrase is repeated.\n",
    "* We can be more confident still if the phrase is repeated that initially starts with \"a\" and the next occurrence starts with \"the\" or \"said\".\n",
    "* \"said\" should be taken as a DET.\n",
    "* There will be between 1 and number of NOUNS entities.\n",
    "* The boundary of an entity will be marked by NOUN NOTNOUN - however this pattern can also occur as part of the noun phrase for the entity.\n",
    "* Entity text sequences will not cross a \":\" or \";\".\n",
    "* Occurrences of an entity will have matching text including at least a matching noun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definite constraints for a well-formed claim:\n",
    "* A NOUN will always form part of an entity;\n",
    "* A singular noun will have a determinant;\n",
    "* An entity will consist of consecutive tokens.\n",
    "* There are no overlaps in occurrences - a word can only be linked to a single entity.\n",
    "* There will be between 1 and number of NOUNS entities.\n",
    "* Entity text sequences will not cross a \":\" or \";\" or \".\" (and possibly a \",\").\n",
    "* The boundary of an entity will be marked by NOUN NOTNOUN - however this pattern can also occur as part of the noun phrase for the entity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to calculate the probability of a set of entities, $ \\boldsymbol E $, given a claim as a sequence of words, $ \\boldsymbol W $: $$ P(\\boldsymbol E | \\boldsymbol W) $$   \n",
    "\n",
    "In fact we want to calculate: $$ \\underset{\\boldsymbol E}{\\operatorname{argmax}} P(\\boldsymbol E | \\boldsymbol W) $$\n",
    "\n",
    "Our claim has a length $ N $:$$\\boldsymbol W = (\\boldsymbol w_0, \\boldsymbol w_1, ..., \\boldsymbol w_{N})$$\n",
    "\n",
    "$N$ may be calculated as the length of the claim in tokens.\n",
    "\n",
    "Each word $\\boldsymbol w_i$ has:\n",
    "* text - $t_i$;\n",
    "* a simple POS tag - $pos_i$;\n",
    "* a more detailed POS tag - $posplus_i$;\n",
    "* a lemma (i.e. a normalised word form) - $lemma_i$; and\n",
    "* dependeny tree information - $dep_i$.\n",
    "\n",
    "I.e. $$ \\boldsymbol w_i = (t_i, pos_i, posplus_i, lemma_i, dep_i) $$\n",
    "\n",
    "We have $ M $ entities: $$\\boldsymbol E = (e_0, e_1, ..., e_{M})$$ \n",
    "\n",
    "where $\\boldsymbol e_0 $ indicates \"no related entity\" or a \"null\" token. $M$ is not known but will be greater than 2 and less than a number of nouns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An occurrence is a set of consecutive tokens: $$ \\boldsymbol o_k = [\\boldsymbol w_i, \\boldsymbol w_{i+1}, ..., \\boldsymbol w_{i+L_{k}}] $$ where $L_k$ is the length of occurrence $k$ which begins at word index $i$.\n",
    "\n",
    "$$ \\boldsymbol W = [o_1, o_2, ..., o_K] $$ where there are $K$ total occurrences in the claim. However, we don't know $K$ for sure. \n",
    "\n",
    "We do know the number of nouns $N_{noun}$. And we know $1 \\leqslant K \\leqslant N_{noun}$. Also $M \\leqslant K$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An entity can have:\n",
    "* a set of one or more occurrences;\n",
    "* a string representation - possibly equal to common text across the set of occurrences;\n",
    "* a number (e.g. be singular or plural).\n",
    "\n",
    "An entity may be though of as a class label that is applied to a word: $$ \\sum_{i=0}^M p(e_i | w) = 1 $$\n",
    "\n",
    "We know that $ p(e_0 | pos = {DET}) = p(e_0 | pos = {NOUN}) = 0 $, i.e. that determinants and nouns will be assigned to some entity. We also know $ p(e_0 | t = \";\") = p(e_0 | t = \":\") = p(e_0 | t = \".\") = 1$.\n",
    "\n",
    "Entities are primarily just groupings of word spans, wherein the grouping creates a discrete entity?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\sum_{i=0}^M P(\\boldsymbol o_k | e_i) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decomposing using Bayes' Rule: \n",
    "\n",
    "$$ \\underset{\\boldsymbol e}{\\operatorname{argmax}} P(\\boldsymbol e | \\boldsymbol w) = {P(\\boldsymbol w | \\boldsymbol e) P(\\boldsymbol e)}/ P(\\boldsymbol w)$$ \n",
    "\n",
    "where we can ignore the denominator as we are looking for argmax: $$ \\underset{\\boldsymbol e}{\\operatorname{argmax}} P(\\boldsymbol e | \\boldsymbol w) = {P(\\boldsymbol w | \\boldsymbol e) P(\\boldsymbol e)}$$\n",
    "\n",
    "In other models $P(\\boldsymbol w | \\boldsymbol e)$ and $P(\\boldsymbol e)$ may be approximated by a product of transitions (e.g. as per a hidden markov model). However, we have dependencies across sets of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each determinant can only be linked to one of the nouns in front of it before the next determinant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by setting each noun as a separate entity? And marking the tokens that are not an entity? Or look at confident selections e.g. DET NOUN [:;.,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can maybe start with a binary classification: $\\boldsymbol e = [0,1]$? No, we can confidently apply a positive determination but our negative determination is unknown, i.e. a word that is not positively marked may still form part of an entity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can estimate $M$ by counting the number of \"a\"/\"an\" determinants + the number of multiple nouns.  \n",
    "\n",
    "Issue multiple nouns are often introduced by \"a X of Ys\".  \n",
    "\n",
    "Also we have \"at least one X\" and \"one or more Ys\" - these may not be introduced by \"a\" or \"an\" and \"at least one\" may be referred to again as \"the at least one\".  \n",
    "\n",
    "Can we use an estimate of number of determinants as a lower bound?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works fairly well for a lower bound / initial estimate.  \n",
    "\n",
    "We can cross check later for missing plural nouns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we model a sequential constraint? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each word $w_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First pass\n",
      "\n",
      " [{}]\n",
      "1 [{}]\n",
      ". [{0: 1}]\n",
      "A [{0: 0}]\n",
      "device [{0: 0}]\n",
      ", [{0: 1}]\n",
      "comprising [{}]\n",
      ": [{0: 1}]\n",
      "\n",
      " [{}]\n",
      "at [{0: 0}]\n",
      "least [{}]\n",
      "one [{}]\n",
      "encrypted [{}]\n",
      "processor [{0: 0}]\n",
      "that [{}]\n",
      "is [{}]\n",
      "configured [{}]\n",
      "to [{}]\n",
      "determine [{}]\n",
      "an [{0: 0}]\n",
      "input [{0: 0}]\n",
      "map [{0: 0}]\n",
      "associated [{}]\n",
      "with [{}]\n",
      "a [{0: 0}]\n",
      "texture [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "and [{}]\n",
      "calculate [{}]\n",
      "a [{0: 0}]\n",
      "reduced [{}]\n",
      "resolution [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "based [{}]\n",
      "on [{}]\n",
      "the [{0: 0}]\n",
      "input [{0: 0}]\n",
      "map [{0: 0}]\n",
      "; [{0: 1}]\n",
      "and [{}]\n",
      "\n",
      " [{}]\n",
      "at [{0: 0}]\n",
      "least [{}]\n",
      "one [{}]\n",
      "second [{}]\n",
      "processor [{0: 0}]\n",
      ", [{0: 1}]\n",
      "communicably [{}]\n",
      "connected [{}]\n",
      "to [{}]\n",
      "the [{0: 0}]\n",
      "at [{}]\n",
      "least [{}]\n",
      "one [{}]\n",
      "encrypted [{}]\n",
      "processor [{0: 0}]\n",
      ", [{0: 1}]\n",
      "that [{0: 0}]\n",
      "is [{}]\n",
      "configured [{}]\n",
      "to [{}]\n",
      ": [{0: 1}]\n",
      "\n",
      " [{}]\n",
      "receive [{}]\n",
      "the [{0: 0}]\n",
      "reduced [{}]\n",
      "resolution [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "and [{}]\n",
      "a [{0: 0}]\n",
      "plurality [{0: 0}]\n",
      "of [{}]\n",
      "similar [{}]\n",
      "patterns [{0: 0}]\n",
      ", [{0: 1}]\n",
      "each [{0: 0}]\n",
      "associated [{}]\n",
      "with [{}]\n",
      "a [{0: 0}]\n",
      "stored [{}]\n",
      "encrypted [{}]\n",
      "map [{0: 0}]\n",
      "template [{0: 0}]\n",
      ", [{0: 1}]\n",
      "and [{}]\n",
      "\n",
      " [{}]\n",
      "identify [{}]\n",
      "a [{0: 0}]\n",
      "match [{0: 0}]\n",
      "- [{}]\n",
      "set [{}]\n",
      "if [{}]\n",
      "a [{0: 0}]\n",
      "match [{0: 0}]\n",
      "exists [{}]\n",
      "between [{}]\n",
      "the [{0: 0}]\n",
      "reduced [{}]\n",
      "resolution [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "and [{}]\n",
      "the [{0: 0}]\n",
      "plurality [{0: 0}]\n",
      "of [{}]\n",
      "similar [{}]\n",
      "patterns [{0: 0}]\n",
      ", [{0: 1}]\n",
      "\n",
      "\n",
      " [{}]\n",
      "wherein [{}]\n",
      "the [{0: 0}]\n",
      "at [{}]\n",
      "least [{}]\n",
      "one [{}]\n",
      "encrypted [{}]\n",
      "processor [{0: 0}]\n",
      "is [{}]\n",
      "further [{}]\n",
      "configured [{}]\n",
      "to [{}]\n",
      "receive [{}]\n",
      "the [{0: 0}]\n",
      "match [{0: 0}]\n",
      "- [{}]\n",
      "set [{0: 0}]\n",
      "and [{}]\n",
      "identify [{}]\n",
      "if [{}]\n",
      "a [{0: 0}]\n",
      "match [{0: 0}]\n",
      "exists [{}]\n",
      "between [{}]\n",
      "the [{0: 0}]\n",
      "input [{0: 0}]\n",
      "map [{0: 0}]\n",
      "and [{}]\n",
      "any [{0: 0}]\n",
      "stored [{}]\n",
      "encrypted [{}]\n",
      "map [{0: 0}]\n",
      "template [{0: 0}]\n",
      "associated [{}]\n",
      "with [{}]\n",
      "the [{0: 0}]\n",
      "match [{0: 0}]\n",
      "- [{}]\n",
      "set [{0: 0}]\n",
      ". [{0: 1}]\n",
      "\n",
      "\n",
      " [{}]\n",
      "Second pass\n",
      "device is e_0=0\n",
      "Next - A is e_0=0\n",
      "Found - A device\n",
      "map is e_0=0\n",
      "Next - input is e_0=0\n",
      "processor is e_0=0\n",
      "Next - at is e_0=0\n",
      "Found - at least one second processor\n",
      "processor is e_0=0\n",
      "Next - the is e_0=0\n",
      "Found - the at least one encrypted processor\n",
      "patterns is e_0=0\n",
      "Next - plurality is e_0=0\n",
      "template is e_0=0\n",
      "Next - map is e_0=0\n",
      "patterns is e_0=0\n",
      "Next - plurality is e_0=0\n",
      "set is e_0=0\n",
      "Next - match is e_0=0\n",
      "\n",
      " [{}]\n",
      "1 [{}]\n",
      ". [{0: 1}]\n",
      "A [{0: 0}]\n",
      "device [{0: 0}]\n",
      ", [{0: 1}]\n",
      "comprising [{}]\n",
      ": [{0: 1}]\n",
      "\n",
      " [{}]\n",
      "at [{0: 0}]\n",
      "least [{}]\n",
      "one [{}]\n",
      "encrypted [{}]\n",
      "processor [{0: 0}]\n",
      "that [{}]\n",
      "is [{}]\n",
      "configured [{}]\n",
      "to [{}]\n",
      "determine [{}]\n",
      "an [{0: 0}]\n",
      "input [{0: 0}]\n",
      "map [{0: 0}]\n",
      "associated [{}]\n",
      "with [{}]\n",
      "a [{0: 0}]\n",
      "texture [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "and [{}]\n",
      "calculate [{}]\n",
      "a [{0: 0}]\n",
      "reduced [{}]\n",
      "resolution [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "based [{}]\n",
      "on [{}]\n",
      "the [{0: 0}]\n",
      "input [{0: 0}]\n",
      "map [{0: 0}]\n",
      "; [{0: 1}]\n",
      "and [{}]\n",
      "\n",
      " [{}]\n",
      "at [{0: 0}]\n",
      "least [{0: 0}]\n",
      "one [{0: 0}]\n",
      "second [{0: 0}]\n",
      "processor [{0: 0}]\n",
      ", [{0: 1}]\n",
      "communicably [{}]\n",
      "connected [{}]\n",
      "to [{}]\n",
      "the [{0: 0}]\n",
      "at [{0: 0}]\n",
      "least [{0: 0}]\n",
      "one [{0: 0}]\n",
      "encrypted [{0: 0}]\n",
      "processor [{0: 0}]\n",
      ", [{0: 1}]\n",
      "that [{0: 0}]\n",
      "is [{}]\n",
      "configured [{}]\n",
      "to [{}]\n",
      ": [{0: 1}]\n",
      "\n",
      " [{}]\n",
      "receive [{}]\n",
      "the [{0: 0}]\n",
      "reduced [{}]\n",
      "resolution [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "and [{}]\n",
      "a [{0: 0}]\n",
      "plurality [{0: 0}]\n",
      "of [{}]\n",
      "similar [{}]\n",
      "patterns [{0: 0}]\n",
      ", [{0: 1}]\n",
      "each [{0: 0}]\n",
      "associated [{}]\n",
      "with [{}]\n",
      "a [{0: 0}]\n",
      "stored [{}]\n",
      "encrypted [{}]\n",
      "map [{0: 0}]\n",
      "template [{0: 0}]\n",
      ", [{0: 1}]\n",
      "and [{}]\n",
      "\n",
      " [{}]\n",
      "identify [{}]\n",
      "a [{0: 0}]\n",
      "match [{0: 0}]\n",
      "- [{}]\n",
      "set [{}]\n",
      "if [{}]\n",
      "a [{0: 0}]\n",
      "match [{0: 0}]\n",
      "exists [{}]\n",
      "between [{}]\n",
      "the [{0: 0}]\n",
      "reduced [{}]\n",
      "resolution [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "and [{}]\n",
      "the [{0: 0}]\n",
      "plurality [{0: 0}]\n",
      "of [{}]\n",
      "similar [{}]\n",
      "patterns [{0: 0}]\n",
      ", [{0: 1}]\n",
      "\n",
      "\n",
      " [{}]\n",
      "wherein [{}]\n",
      "the [{0: 0}]\n",
      "at [{}]\n",
      "least [{}]\n",
      "one [{}]\n",
      "encrypted [{}]\n",
      "processor [{0: 0}]\n",
      "is [{}]\n",
      "further [{}]\n",
      "configured [{}]\n",
      "to [{}]\n",
      "receive [{}]\n",
      "the [{0: 0}]\n",
      "match [{0: 0}]\n",
      "- [{}]\n",
      "set [{0: 0}]\n",
      "and [{}]\n",
      "identify [{}]\n",
      "if [{}]\n",
      "a [{0: 0}]\n",
      "match [{0: 0}]\n",
      "exists [{}]\n",
      "between [{}]\n",
      "the [{0: 0}]\n",
      "input [{0: 0}]\n",
      "map [{0: 0}]\n",
      "and [{}]\n",
      "any [{0: 0}]\n",
      "stored [{}]\n",
      "encrypted [{}]\n",
      "map [{0: 0}]\n",
      "template [{0: 0}]\n",
      "associated [{}]\n",
      "with [{}]\n",
      "the [{0: 0}]\n",
      "match [{0: 0}]\n",
      "- [{}]\n",
      "set [{0: 0}]\n",
      ". [{0: 1}]\n",
      "\n",
      "\n",
      " [{}]\n",
      "Third pass\n",
      ". is e_0=1 - looking back\n",
      ", is e_0=1 - looking back\n",
      "Next - device is e_0=0 and noun\n",
      "Next - A is e_0=0 and DET\n",
      "Last break set to 5\n",
      ": is e_0=1 - looking back\n",
      "; is e_0=1 - looking back\n",
      "Next - map is e_0=0 and noun\n",
      "Next - the is e_0=0 and DET\n",
      "Last break set to 38\n",
      ", is e_0=1 - looking back\n",
      "Next - processor is e_0=0 and noun\n",
      ", is e_0=1 - looking back\n",
      "Next - processor is e_0=0 and noun\n",
      "Next - the is e_0=0 and DET\n",
      "Last break set to 56\n",
      ": is e_0=1 - looking back\n",
      ", is e_0=1 - looking back\n",
      "Next - patterns is e_0=0 and noun\n",
      ", is e_0=1 - looking back\n",
      "Next - template is e_0=0 and noun\n",
      ", is e_0=1 - looking back\n",
      "Next - patterns is e_0=0 and noun\n",
      ". is e_0=1 - looking back\n",
      "Next - set is e_0=0 and noun\n",
      "\n",
      "--------\n",
      "\n",
      "Looking for matches for 'A device'\n",
      "Looking for matches for 'the input map'\n",
      "Looking for matches for 'the at least one encrypted processor'\n",
      "Unique entities include ['device', 'at least one encrypted processor', 'input map']\n",
      "[A device]\n",
      "[the at least one encrypted processor]\n",
      "[the input map]\n",
      "\n",
      " [{}]\n",
      "1 [{}]\n",
      ". [{0: 1}]\n",
      "A [{0: 0, 1: 1}]\n",
      "device [{0: 0, 1: 1}]\n",
      ", [{0: 1}]\n",
      "comprising [{}]\n",
      ": [{0: 1}]\n",
      "\n",
      " [{}]\n",
      "at [{0: 0}]\n",
      "least [{}]\n",
      "one [{}]\n",
      "encrypted [{}]\n",
      "processor [{0: 0}]\n",
      "that [{}]\n",
      "is [{}]\n",
      "configured [{}]\n",
      "to [{}]\n",
      "determine [{}]\n",
      "an [{0: 0}]\n",
      "input [{0: 0}]\n",
      "map [{0: 0}]\n",
      "associated [{}]\n",
      "with [{}]\n",
      "a [{0: 0}]\n",
      "texture [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "and [{}]\n",
      "calculate [{}]\n",
      "a [{0: 0}]\n",
      "reduced [{}]\n",
      "resolution [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "based [{}]\n",
      "on [{}]\n",
      "the [{0: 0, 3: 1}]\n",
      "input [{0: 0, 3: 1}]\n",
      "map [{0: 0, 3: 1}]\n",
      "; [{0: 1}]\n",
      "and [{}]\n",
      "\n",
      " [{}]\n",
      "at [{0: 0}]\n",
      "least [{0: 0}]\n",
      "one [{0: 0}]\n",
      "second [{0: 0}]\n",
      "processor [{0: 0}]\n",
      ", [{0: 1}]\n",
      "communicably [{}]\n",
      "connected [{}]\n",
      "to [{}]\n",
      "the [{0: 0, 2: 1}]\n",
      "at [{0: 0, 2: 1}]\n",
      "least [{0: 0, 2: 1}]\n",
      "one [{0: 0, 2: 1}]\n",
      "encrypted [{0: 0, 2: 1}]\n",
      "processor [{0: 0, 2: 1}]\n",
      ", [{0: 1}]\n",
      "that [{0: 0}]\n",
      "is [{}]\n",
      "configured [{}]\n",
      "to [{}]\n",
      ": [{0: 1}]\n",
      "\n",
      " [{}]\n",
      "receive [{}]\n",
      "the [{0: 0}]\n",
      "reduced [{}]\n",
      "resolution [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "and [{}]\n",
      "a [{0: 0}]\n",
      "plurality [{0: 0}]\n",
      "of [{}]\n",
      "similar [{}]\n",
      "patterns [{0: 0}]\n",
      ", [{0: 1}]\n",
      "each [{0: 0}]\n",
      "associated [{}]\n",
      "with [{}]\n",
      "a [{0: 0}]\n",
      "stored [{}]\n",
      "encrypted [{}]\n",
      "map [{0: 0}]\n",
      "template [{0: 0}]\n",
      ", [{0: 1}]\n",
      "and [{}]\n",
      "\n",
      " [{}]\n",
      "identify [{}]\n",
      "a [{0: 0}]\n",
      "match [{0: 0}]\n",
      "- [{}]\n",
      "set [{}]\n",
      "if [{}]\n",
      "a [{0: 0}]\n",
      "match [{0: 0}]\n",
      "exists [{}]\n",
      "between [{}]\n",
      "the [{0: 0}]\n",
      "reduced [{}]\n",
      "resolution [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "and [{}]\n",
      "the [{0: 0}]\n",
      "plurality [{0: 0}]\n",
      "of [{}]\n",
      "similar [{}]\n",
      "patterns [{0: 0}]\n",
      ", [{0: 1}]\n",
      "\n",
      "\n",
      " [{}]\n",
      "wherein [{}]\n",
      "the [{0: 0}]\n",
      "at [{}]\n",
      "least [{}]\n",
      "one [{}]\n",
      "encrypted [{}]\n",
      "processor [{0: 0}]\n",
      "is [{}]\n",
      "further [{}]\n",
      "configured [{}]\n",
      "to [{}]\n",
      "receive [{}]\n",
      "the [{0: 0}]\n",
      "match [{0: 0}]\n",
      "- [{}]\n",
      "set [{0: 0}]\n",
      "and [{}]\n",
      "identify [{}]\n",
      "if [{}]\n",
      "a [{0: 0}]\n",
      "match [{0: 0}]\n",
      "exists [{}]\n",
      "between [{}]\n",
      "the [{0: 0}]\n",
      "input [{0: 0}]\n",
      "map [{0: 0}]\n",
      "and [{}]\n",
      "any [{0: 0}]\n",
      "stored [{}]\n",
      "encrypted [{}]\n",
      "map [{0: 0}]\n",
      "template [{0: 0}]\n",
      "associated [{}]\n",
      "with [{}]\n",
      "the [{0: 0}]\n",
      "match [{0: 0}]\n",
      "- [{}]\n",
      "set [{0: 0}]\n",
      ". [{0: 1}]\n",
      "\n",
      "\n",
      " [{}]\n",
      "{'reduced resolution pattern': [a reduced resolution pattern, the reduced resolution pattern, the reduced resolution pattern], 'stored encrypted map template': [a stored encrypted map template, any stored encrypted map template], 'device': [A device], 'at least one second processor': [at least one second processor], 'texture pattern': [a texture pattern], 'match': [a match, a match], 'similar patterns': [similar patterns, similar patterns], 'match-set': [the match-set, the match-set], 'at least one encrypted processor': [at least one encrypted processor, the at least one encrypted processor, the at least one encrypted processor], 'plurality': [a plurality, the plurality], 'input map': [an input map, the input map, the input map]}\n",
      "([A device, comprising:\n",
      "at least one encrypted processor, an input map, a texture pattern, a reduced resolution pattern, the input map, the at least one encrypted processor, , the reduced resolution pattern, a plurality of similar patterns, , a stored encrypted map template, a match, a match, the reduced resolution pattern, the plurality of similar patterns, the at least one encrypted processor, the match-set, a match, the input map, any stored encrypted map template], {'reduced resolution pattern': [a reduced resolution pattern, the reduced resolution pattern, the reduced resolution pattern], '': [, ], 'input map': [an input map, the input map, the input map], 'stored encrypted map template': [a stored encrypted map template, any stored encrypted map template], 'texture pattern': [a texture pattern], 'plurality of similar patterns': [a plurality of similar patterns, the plurality of similar patterns], 'device, comprising:\\nat least one encrypted processor': [A device, comprising:\n",
      "at least one encrypted processor], 'match': [a match, a match, a match], 'at least one encrypted processor': [the at least one encrypted processor, the at least one encrypted processor], 'match-set': [the match-set]})\n"
     ]
    }
   ],
   "source": [
    "# This is our good algorithm\n",
    "\n",
    "# Start with all words relate to no entities\n",
    "p_all_e_word = dict()\n",
    "\n",
    "def check_start_phrase(token, doc):\n",
    "    \"\"\" Check for start of phrases 'at least one' and 'one or more' as determinant.\n",
    "    \n",
    "    Return true if located.\"\"\"\n",
    "    i = token.i\n",
    "    condition = (\n",
    "        doc[i:i+3].text.lower() == \"at least one\" or\n",
    "        doc[i:i+3].text.lower() == \"one or more\"\n",
    "    )\n",
    "    condition = condition and (doc[i-1].text.lower() != \"the\")\n",
    "    return condition\n",
    "\n",
    "def is_det(token, doc):\n",
    "    \"\"\" Wrapper function for determinant check.\"\"\"\n",
    "    # Add 'said' as custom determination\n",
    "    condition = (token.pos == DET or token.text == \"said\")\n",
    "    # Alternatively we can have the start phrases as above\n",
    "    condition = (condition or check_start_phrase(token, doc))\n",
    "    # Add check for 'a)' and 'a.' - this is not a det\n",
    "    condition = condition and (doc[token.i:token.i+2].text.lower() not in ['a)', 'a.'])\n",
    "    return condition\n",
    "\n",
    "# 6 is a good test claim\n",
    "doc = nlp_docs[4]\n",
    "noun_count = list()\n",
    "\n",
    "# Initialise probabilities\n",
    "for token in doc:\n",
    "    p_all_e_word[token] = dict()\n",
    "\n",
    "# First parse of tokens\n",
    "for token in doc:\n",
    "    p_all_e_word[token] = dict()\n",
    "    if is_det(token, doc):\n",
    "        p_all_e_word[token][0] = 0\n",
    "        # Also set next word as an entity\n",
    "        p_all_e_word[doc[token.i+1]][0] = 0\n",
    "    elif token.pos == NOUN:\n",
    "        p_all_e_word[token][0] = 0\n",
    "        noun_count.append(token)\n",
    "    if token.text in [\":\",\";\",\".\", \",\"]:\n",
    "        p_all_e_word[token][0] = 1\n",
    "\n",
    "print(\"First pass\")\n",
    "for token in doc:\n",
    "    print(token.text, \"[{0}]\".format(p_all_e_word[token]), end = '\\n') \n",
    "#print(\"Number of nouns = {0}\".format(len(noun_count)))\n",
    "\n",
    "print(\"Second pass\")\n",
    "# Second parse to fill in probabilities given hard end points\n",
    "last_break = 0\n",
    "for token in doc:\n",
    "    # Look for hard end points\n",
    "    if p_all_e_word[token].get(0, None) == 1:\n",
    "        # Look at previous token\n",
    "        previous_word = doc[token.i - 1]\n",
    "        # If it is set as an entity (i.e. e_0=0)\n",
    "        if p_all_e_word[previous_word].get(0, None) == 0:\n",
    "            print(\"{0} is e_0=0\".format(previous_word))\n",
    "            # Go back to next e_0=0 entry\n",
    "            for j in range(token.i-2, last_break, -1):\n",
    "                if p_all_e_word[doc[j]].get(0, None) == 0:\n",
    "                    # If last e_0=0 entry is a determinant\n",
    "                    print(\"Next - {0} is e_0=0\".format(doc[j]))\n",
    "                    if is_det(doc[j], doc):\n",
    "                        print(\"Found - {0}\".format(doc[j:token.i]))\n",
    "                        # Set in between tokens as e_0=0\n",
    "                        for k in range(j+1, token.i):\n",
    "                            p_all_e_word[doc[k]][0] = 0 \n",
    "                    # Finish when hitting previous e_0 token\n",
    "                    break\n",
    "\n",
    "                    \n",
    "for token in doc:\n",
    "    print(token.text, \"[{0}]\".format(p_all_e_word[token]), end = '\\n') \n",
    "#print(\"Number of nouns = {0}\".format(len(noun_count)))\n",
    "\n",
    "print(\"Third pass\") \n",
    "# Third parse - take any DET ... NOUN <boundary> portions\n",
    "last_break = 0\n",
    "spans_to_match = list()\n",
    "for token in doc:\n",
    "    # Look for hard end points\n",
    "    if p_all_e_word[token].get(0, None) == 1:\n",
    "        print(\"{0} is e_0=1 - looking back\".format(token))\n",
    "        # See if there is a continuous set of e_0 = 0 ending with a noun and starting with a DET\n",
    "        for j in range(token.i-1, last_break, -1):\n",
    "            # Look for e_0=0 and noun (do we need to limit to singular noun)\n",
    "            if p_all_e_word[doc[j]].get(0, None) == 0 and doc[j].pos == NOUN:\n",
    "                print(\"Next - {0} is e_0=0 and noun\".format(doc[j]))\n",
    "                # Look back for DET\n",
    "                for k in range(j, last_break, -1):\n",
    "                    if p_all_e_word[doc[k]].get(0, None) != 0:\n",
    "                        # Exit if don't meet a e_0 token\n",
    "                        break\n",
    "                    elif doc[k].pos == DET:\n",
    "                        print(\"Next - {0} is e_0=0 and DET\".format(doc[k]))\n",
    "                        print(\"Last break set to {0}\".format(token.i))\n",
    "                        spans_to_match.append((k,j+1))\n",
    "                        last_break = token.i\n",
    "                        break\n",
    "                break\n",
    "                \n",
    "print(\"\\n--------\\n\")\n",
    "\n",
    "entity_dict = dict()\n",
    "for stm in spans_to_match:\n",
    "    print(\"Looking for matches for '{0}'\".format(doc[stm[0]:stm[1]]))\n",
    "    non_det_string = doc[stm[0]+1:stm[1]].text\n",
    "    if non_det_string not in entity_dict.keys():\n",
    "        entity_dict[non_det_string] = list()\n",
    "    entity_dict[non_det_string].append(doc[stm[0]:stm[1]])\n",
    "    \n",
    "print(\"Unique entities include {0}\".format(list(entity_dict.keys()))) \n",
    "\n",
    "#Add entity values\n",
    "entity_count = 0\n",
    "for entity_string in entity_dict.keys():\n",
    "    entity_occurrences = entity_dict[entity_string]\n",
    "    entity_count += 1\n",
    "    print(entity_dict[entity_string])\n",
    "    for occurrence in entity_occurrences:\n",
    "        for token in occurrence:\n",
    "            p_all_e_word[token][entity_count] = 1\n",
    "        \n",
    "for token in doc:\n",
    "    print(token.text, \"[{0}]\".format(p_all_e_word[token]), end = '\\n') \n",
    "\n",
    "# Compare with existing methods \n",
    "print(np_entity_finder(doc))\n",
    "print(simple_spacy_entity_finder(doc))\n",
    "\n",
    "# Here look for matches that are found with both methods that have an [\"a ...\",\"the ...\", ...] pattern "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heuristics:\n",
    "* \"for\" marks a non-entity [e_0=1]\n",
    "* \"DET X of ...\" [e_0=0]\n",
    "* \"in X with\" [e_0=1]\n",
    "* \"at least one\" / \"one or more\" [e_0=0]\n",
    "* lemma = \\[\"comprise\", \"have\", \"be\", \"include\"\\] [e_0=1]\n",
    "* \"where\" in token.text [e_0=1] (e.g. \"where or wherein\")\n",
    "* \"associated with\" [e_0=1]\n",
    "* \"configured/adapted to\" [e_0=0]\n",
    "\n",
    "Also watch out for \"each of the plurality of X\" or \"at least one of the plurality of X\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import NUM\n",
    "\n",
    "\n",
    "\n",
    "# We want to set these if they are not already set\n",
    "def set_probability(token, p_all_e_word, entity, new_value):\n",
    "    \"\"\" Set probability value if not set already\"\"\"\n",
    "    if entity not in p_all_e_word[token].keys():\n",
    "        if sum([v for k, v in p_all_e_word[token]] + new_value) <= 1: \n",
    "            p_all_e_word[token][entity] = new_value\n",
    "    return p_all_e_word\n",
    "            \n",
    "\n",
    "def heuristics(token, doc, p_all_e_word):\n",
    "    \"\"\" Apply heuristics to mark entity probabilities\"\"\"\n",
    "    entity_stop_chars = [\"\\n\",\":\",\";\",\".\", \",\"]\n",
    "    # Set stop characters as non-entity\n",
    "    if token.text in entity_stop_chars:\n",
    "        p_all_e_word[token][0] = 1\n",
    "    \n",
    "    # Set noun as entity\n",
    "    if token.pos == NOUN:\n",
    "        p_all_e_word[token][0] = 0\n",
    "    \n",
    "    # 'for' is an entity boundary\n",
    "    if token.lemma_ == \"for\":\n",
    "        p_all_e_word[token][0] = 1\n",
    "    \n",
    "    # \"comprise\", \"have\", \"be\", \"include\" do not relate to an entity\n",
    "    if token.lemma_ in [\"comprise\", \"have\", \"be\", \"include\"]:\n",
    "        p_all_e_word[token][0] = 1\n",
    "    \n",
    "    # \"where\" and \"wherein\" do not relate to an entity\n",
    "    if \"where\" in token.lemma_:\n",
    "         p_all_e_word[token][0] = 1\n",
    "    \n",
    "    # Look ahead - check not at end\n",
    "    if token.i < (len(doc)-1):\n",
    "        \n",
    "        # \"configured/adapted to\" do not relate to an entity\n",
    "        if doc[token.i+1].lemma_ == \"to\" and token.lemma_ in [\"configure\", \"adapt\"]:\n",
    "            p_all_e_word[token][0] = 1\n",
    "            p_all_e_word[doc[token.i + 1]][0] = 1\n",
    "    \n",
    "    if token.i < (len(doc)-2):\n",
    "        # Set DETs as entity\n",
    "        if (\n",
    "            token.pos == DET or token.text == \"said\"\n",
    "        ) and (\n",
    "            doc[token.i:token.i+2].text.lower() not in ['a)', 'a.']\n",
    "        ):\n",
    "            p_all_e_word[token][0] = 0\n",
    "            p_all_e_word[doc[token.i+1]][0] = 0\n",
    "            \n",
    "        # DET X of .. relates to an entity\n",
    "        if token.pos == DET and doc[token.i+2].lemma_ == \"of\":\n",
    "            p_all_e_word[token][0] = 0\n",
    "            p_all_e_word[doc[token.i + 1]][0] = 0\n",
    "            # Set of\n",
    "            p_all_e_word[doc[token.i + 2]][0] = 0\n",
    "            # Set term after off\n",
    "            p_all_e_word[doc[token.i + 3]][0] = 0\n",
    "            \n",
    "        # \"in X with\" does not relate to an entity\n",
    "        if token.lemma_ == \"in\" and doc[token.i+2].lemma_ == \"with\":\n",
    "            p_all_e_word[token][0] = 1\n",
    "            p_all_e_word[doc[token.i + 1]][0] = 1\n",
    "            p_all_e_word[doc[token.i + 2]][0] = 1\n",
    "            \n",
    "        # Associated with does not relate to an entity\n",
    "        if doc[token.i:token.i+2].text.lower() == \"associated with\":\n",
    "            p_all_e_word[token][0] = 1\n",
    "            p_all_e_word[doc[token.i + 1]][0] = 1\n",
    "    \n",
    "    if token.i < (len(doc)-3):\n",
    "        # \"at least NUM\" / \"NUM or more\" relates to an entity\n",
    "        if doc[token.i:token.i + 2].text.lower() == \"at least\" and doc[token.i + 2].pos == NUM:\n",
    "            p_all_e_word[token][0] = 0\n",
    "            p_all_e_word[doc[token.i + 1]][0] = 0\n",
    "            p_all_e_word[doc[token.i + 2]][0] = 0\n",
    "        if doc[token.i+1:token.i + 3].text.lower() == \"or more\" and token.pos == NUM:\n",
    "            p_all_e_word[token][0] = 0\n",
    "            p_all_e_word[doc[token.i + 1]][0] = 0\n",
    "            p_all_e_word[doc[token.i + 2]][0] = 0\n",
    "    \n",
    "    return p_all_e_word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First pass - entity label heuristics\n",
      "\n",
      " [{0: 1}]\n",
      "1 [{}]\n",
      ". [{0: 1}]\n",
      "A [{0: 0}]\n",
      "device [{0: 0}]\n",
      ", [{0: 1}]\n",
      "comprising [{0: 1}]\n",
      ": [{0: 1}]\n",
      "\n",
      " [{0: 1}]\n",
      "at [{0: 0}]\n",
      "least [{0: 0}]\n",
      "one [{0: 0}]\n",
      "encrypted [{}]\n",
      "processor [{0: 0}]\n",
      "that [{}]\n",
      "is [{0: 1}]\n",
      "configured [{0: 1}]\n",
      "to [{0: 1}]\n",
      "determine [{}]\n",
      "an [{0: 0}]\n",
      "input [{0: 0}]\n",
      "map [{0: 0}]\n",
      "associated [{0: 1}]\n",
      "with [{0: 1}]\n",
      "a [{0: 0}]\n",
      "texture [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "and [{}]\n",
      "calculate [{}]\n",
      "a [{0: 0}]\n",
      "reduced [{0: 0}]\n",
      "resolution [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "based [{}]\n",
      "on [{}]\n",
      "the [{0: 0}]\n",
      "input [{0: 0}]\n",
      "map [{0: 0}]\n",
      "; [{0: 1}]\n",
      "and [{}]\n",
      "\n",
      " [{0: 1}]\n",
      "at [{0: 0}]\n",
      "least [{0: 0}]\n",
      "one [{0: 0}]\n",
      "second [{}]\n",
      "processor [{0: 0}]\n",
      ", [{0: 1}]\n",
      "communicably [{}]\n",
      "connected [{}]\n",
      "to [{}]\n",
      "the [{0: 0}]\n",
      "at [{0: 0}]\n",
      "least [{0: 0}]\n",
      "one [{0: 0}]\n",
      "encrypted [{}]\n",
      "processor [{0: 0}]\n",
      ", [{0: 1}]\n",
      "that [{0: 0}]\n",
      "is [{0: 1}]\n",
      "configured [{0: 1}]\n",
      "to [{0: 1}]\n",
      ": [{0: 1}]\n",
      "\n",
      " [{0: 1}]\n",
      "receive [{}]\n",
      "the [{0: 0}]\n",
      "reduced [{0: 0}]\n",
      "resolution [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "and [{}]\n",
      "a [{0: 0}]\n",
      "plurality [{0: 0}]\n",
      "of [{0: 0}]\n",
      "similar [{0: 0}]\n",
      "patterns [{0: 0}]\n",
      ", [{0: 1}]\n",
      "each [{0: 0}]\n",
      "associated [{0: 1}]\n",
      "with [{0: 1}]\n",
      "a [{0: 0}]\n",
      "stored [{0: 0}]\n",
      "encrypted [{}]\n",
      "map [{0: 0}]\n",
      "template [{0: 0}]\n",
      ", [{0: 1}]\n",
      "and [{}]\n",
      "\n",
      " [{0: 1}]\n",
      "identify [{}]\n",
      "a [{0: 0}]\n",
      "match [{0: 0}]\n",
      "- [{}]\n",
      "set [{}]\n",
      "if [{}]\n",
      "a [{0: 0}]\n",
      "match [{0: 0}]\n",
      "exists [{}]\n",
      "between [{}]\n",
      "the [{0: 0}]\n",
      "reduced [{0: 0}]\n",
      "resolution [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "and [{}]\n",
      "the [{0: 0}]\n",
      "plurality [{0: 0}]\n",
      "of [{0: 0}]\n",
      "similar [{0: 0}]\n",
      "patterns [{0: 0}]\n",
      ", [{0: 1}]\n",
      "\n",
      "\n",
      " [{}]\n",
      "wherein [{0: 1}]\n",
      "the [{0: 0}]\n",
      "at [{0: 0}]\n",
      "least [{0: 0}]\n",
      "one [{0: 0}]\n",
      "encrypted [{}]\n",
      "processor [{0: 0}]\n",
      "is [{0: 1}]\n",
      "further [{}]\n",
      "configured [{0: 1}]\n",
      "to [{0: 1}]\n",
      "receive [{}]\n",
      "the [{0: 0}]\n",
      "match [{0: 0}]\n",
      "- [{}]\n",
      "set [{0: 0}]\n",
      "and [{}]\n",
      "identify [{}]\n",
      "if [{}]\n",
      "a [{0: 0}]\n",
      "match [{0: 0}]\n",
      "exists [{}]\n",
      "between [{}]\n",
      "the [{0: 0}]\n",
      "input [{0: 0}]\n",
      "map [{0: 0}]\n",
      "and [{}]\n",
      "any [{0: 0}]\n",
      "stored [{0: 0}]\n",
      "encrypted [{}]\n",
      "map [{0: 0}]\n",
      "template [{0: 0}]\n",
      "associated [{0: 1}]\n",
      "with [{0: 1}]\n",
      "the [{0: 0}]\n",
      "match [{0: 0}]\n",
      "- [{}]\n",
      "set [{0: 0}]\n",
      ". [{0: 1}]\n",
      "\n",
      "\n",
      " [{}]\n",
      "Second pass - look for DET ... NOUN groupings\n",
      "\n",
      " is e_0=1 or DET - looking back\n",
      ". is e_0=1 or DET - looking back\n",
      "Step back token - 1 with pos - 95\n",
      "Setting non-Noun\n",
      "A is e_0=1 or DET - looking back\n",
      "Step back token - . with pos - 95\n",
      "Setting non-Noun\n",
      "Step back token - 1 with pos - 95\n",
      "Setting non-Noun\n",
      ", is e_0=1 or DET - looking back\n",
      "Step back token - device with pos - 90\n",
      "comprising is e_0=1 or DET - looking back\n",
      "Step back token - , with pos - 95\n",
      "Setting non-Noun\n",
      ": is e_0=1 or DET - looking back\n",
      "Step back token - comprising with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - , with pos - 95\n",
      "Setting non-Noun\n",
      "\n",
      " is e_0=1 or DET - looking back\n",
      "Step back token - : with pos - 95\n",
      "Setting non-Noun\n",
      "Step back token - comprising with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - , with pos - 95\n",
      "Setting non-Noun\n",
      "is is e_0=1 or DET - looking back\n",
      "Step back token - that with pos - 82\n",
      "Setting non-Noun\n",
      "Step back token - processor with pos - 90\n",
      "configured is e_0=1 or DET - looking back\n",
      "Step back token - is with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - that with pos - 82\n",
      "Setting non-Noun\n",
      "to is e_0=1 or DET - looking back\n",
      "Step back token - configured with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - is with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - that with pos - 82\n",
      "Setting non-Noun\n",
      "an is e_0=1 or DET - looking back\n",
      "Step back token - determine with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - to with pos - 92\n",
      "Setting non-Noun\n",
      "Step back token - configured with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - is with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - that with pos - 82\n",
      "Setting non-Noun\n",
      "associated is e_0=1 or DET - looking back\n",
      "Step back token - map with pos - 90\n",
      "with is e_0=1 or DET - looking back\n",
      "Step back token - associated with pos - 98\n",
      "Setting non-Noun\n",
      "a is e_0=1 or DET - looking back\n",
      "Step back token - with with pos - 83\n",
      "Setting non-Noun\n",
      "Step back token - associated with pos - 98\n",
      "Setting non-Noun\n",
      "a is e_0=1 or DET - looking back\n",
      "Step back token - calculate with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - and with pos - 87\n",
      "Setting non-Noun\n",
      "Step back token - pattern with pos - 90\n",
      "the is e_0=1 or DET - looking back\n",
      "Step back token - on with pos - 83\n",
      "Setting non-Noun\n",
      "Step back token - based with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - pattern with pos - 90\n",
      "; is e_0=1 or DET - looking back\n",
      "Step back token - map with pos - 90\n",
      "\n",
      " is e_0=1 or DET - looking back\n",
      "Step back token - and with pos - 87\n",
      "Setting non-Noun\n",
      "Step back token - ; with pos - 95\n",
      "Setting non-Noun\n",
      ", is e_0=1 or DET - looking back\n",
      "Step back token - processor with pos - 90\n",
      "the is e_0=1 or DET - looking back\n",
      "Step back token - to with pos - 83\n",
      "Setting non-Noun\n",
      "Step back token - connected with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - communicably with pos - 84\n",
      "Setting non-Noun\n",
      "Step back token - , with pos - 95\n",
      "Setting non-Noun\n",
      ", is e_0=1 or DET - looking back\n",
      "Step back token - processor with pos - 90\n",
      "that is e_0=1 or DET - looking back\n",
      "Step back token - , with pos - 95\n",
      "Setting non-Noun\n",
      "to is e_0=1 or DET - looking back\n",
      "Step back token - configured with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - is with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - that with pos - 88\n",
      "Setting non-Noun\n",
      "Step back token - , with pos - 95\n",
      "Setting non-Noun\n",
      ": is e_0=1 or DET - looking back\n",
      "Step back token - to with pos - 83\n",
      "Setting non-Noun\n",
      "Step back token - configured with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - is with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - that with pos - 88\n",
      "Setting non-Noun\n",
      "Step back token - , with pos - 95\n",
      "Setting non-Noun\n",
      "\n",
      " is e_0=1 or DET - looking back\n",
      "Step back token - : with pos - 95\n",
      "Setting non-Noun\n",
      "Step back token - to with pos - 83\n",
      "Setting non-Noun\n",
      "Step back token - configured with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - is with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - that with pos - 88\n",
      "Setting non-Noun\n",
      "Step back token - , with pos - 95\n",
      "Setting non-Noun\n",
      "the is e_0=1 or DET - looking back\n",
      "Step back token - receive with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - \n",
      " with pos - 101\n",
      "Setting non-Noun\n",
      "Step back token - : with pos - 95\n",
      "Setting non-Noun\n",
      "Step back token - to with pos - 83\n",
      "Setting non-Noun\n",
      "Step back token - configured with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - is with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - that with pos - 88\n",
      "Setting non-Noun\n",
      "Step back token - , with pos - 95\n",
      "Setting non-Noun\n",
      "a is e_0=1 or DET - looking back\n",
      "Step back token - and with pos - 87\n",
      "Setting non-Noun\n",
      "Step back token - pattern with pos - 90\n",
      ", is e_0=1 or DET - looking back\n",
      "Step back token - patterns with pos - 90\n",
      "each is e_0=1 or DET - looking back\n",
      "Step back token - , with pos - 95\n",
      "Setting non-Noun\n",
      "with is e_0=1 or DET - looking back\n",
      "Step back token - associated with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - each with pos - 88\n",
      "Setting non-Noun\n",
      "Step back token - , with pos - 95\n",
      "Setting non-Noun\n",
      "a is e_0=1 or DET - looking back\n",
      "Step back token - with with pos - 83\n",
      "Setting non-Noun\n",
      "Step back token - associated with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - each with pos - 88\n",
      "Setting non-Noun\n",
      "Step back token - , with pos - 95\n",
      "Setting non-Noun\n",
      ", is e_0=1 or DET - looking back\n",
      "Step back token - template with pos - 90\n",
      "\n",
      " is e_0=1 or DET - looking back\n",
      "Step back token - and with pos - 87\n",
      "Setting non-Noun\n",
      "Step back token - , with pos - 95\n",
      "Setting non-Noun\n",
      "a is e_0=1 or DET - looking back\n",
      "Step back token - identify with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - \n",
      " with pos - 101\n",
      "Setting non-Noun\n",
      "Step back token - and with pos - 87\n",
      "Setting non-Noun\n",
      "Step back token - , with pos - 95\n",
      "Setting non-Noun\n",
      "a is e_0=1 or DET - looking back\n",
      "Step back token - if with pos - 83\n",
      "Setting non-Noun\n",
      "Step back token - set with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - - with pos - 95\n",
      "Setting non-Noun\n",
      "Step back token - match with pos - 90\n",
      "the is e_0=1 or DET - looking back\n",
      "Step back token - between with pos - 83\n",
      "Setting non-Noun\n",
      "Step back token - exists with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - match with pos - 90\n",
      "the is e_0=1 or DET - looking back\n",
      "Step back token - and with pos - 87\n",
      "Setting non-Noun\n",
      "Step back token - pattern with pos - 90\n",
      ", is e_0=1 or DET - looking back\n",
      "Step back token - patterns with pos - 90\n",
      "wherein is e_0=1 or DET - looking back\n",
      "Step back token - \n",
      "\n",
      " with pos - 101\n",
      "Setting non-Noun\n",
      "Step back token - , with pos - 95\n",
      "Setting non-Noun\n",
      "the is e_0=1 or DET - looking back\n",
      "Step back token - wherein with pos - 84\n",
      "Setting non-Noun\n",
      "Step back token - \n",
      "\n",
      " with pos - 101\n",
      "Setting non-Noun\n",
      "Step back token - , with pos - 95\n",
      "Setting non-Noun\n",
      "is is e_0=1 or DET - looking back\n",
      "Step back token - processor with pos - 90\n",
      "configured is e_0=1 or DET - looking back\n",
      "Step back token - further with pos - 84\n",
      "Setting non-Noun\n",
      "Step back token - is with pos - 98\n",
      "Setting non-Noun\n",
      "to is e_0=1 or DET - looking back\n",
      "Step back token - configured with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - further with pos - 84\n",
      "Setting non-Noun\n",
      "Step back token - is with pos - 98\n",
      "Setting non-Noun\n",
      "the is e_0=1 or DET - looking back\n",
      "Step back token - receive with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - to with pos - 92\n",
      "Setting non-Noun\n",
      "Step back token - configured with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - further with pos - 84\n",
      "Setting non-Noun\n",
      "Step back token - is with pos - 98\n",
      "Setting non-Noun\n",
      "a is e_0=1 or DET - looking back\n",
      "Step back token - if with pos - 83\n",
      "Setting non-Noun\n",
      "Step back token - identify with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - and with pos - 87\n",
      "Setting non-Noun\n",
      "Step back token - set with pos - 90\n",
      "the is e_0=1 or DET - looking back\n",
      "Step back token - between with pos - 83\n",
      "Setting non-Noun\n",
      "Step back token - exists with pos - 98\n",
      "Setting non-Noun\n",
      "Step back token - match with pos - 90\n",
      "any is e_0=1 or DET - looking back\n",
      "Step back token - and with pos - 87\n",
      "Setting non-Noun\n",
      "Step back token - map with pos - 90\n",
      "associated is e_0=1 or DET - looking back\n",
      "Step back token - template with pos - 90\n",
      "with is e_0=1 or DET - looking back\n",
      "Step back token - associated with pos - 98\n",
      "Setting non-Noun\n",
      "the is e_0=1 or DET - looking back\n",
      "Step back token - with with pos - 83\n",
      "Setting non-Noun\n",
      "Step back token - associated with pos - 98\n",
      "Setting non-Noun\n",
      ". is e_0=1 or DET - looking back\n",
      "Step back token - set with pos - 90\n",
      "\n",
      " [{0: 1}]\n",
      "1 [{0: 1}]\n",
      ". [{0: 1}]\n",
      "A [{0: 0}]\n",
      "device [{0: 0}]\n",
      ", [{0: 1}]\n",
      "comprising [{0: 1}]\n",
      ": [{0: 1}]\n",
      "\n",
      " [{0: 1}]\n",
      "at [{0: 0}]\n",
      "least [{0: 0}]\n",
      "one [{0: 0}]\n",
      "encrypted [{0: 0}]\n",
      "processor [{0: 0}]\n",
      "that [{0: 1}]\n",
      "is [{0: 1}]\n",
      "configured [{0: 1}]\n",
      "to [{0: 1}]\n",
      "determine [{0: 1}]\n",
      "an [{0: 0}]\n",
      "input [{0: 0}]\n",
      "map [{0: 0}]\n",
      "associated [{0: 1}]\n",
      "with [{0: 1}]\n",
      "a [{0: 0}]\n",
      "texture [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "and [{0: 1}]\n",
      "calculate [{0: 1}]\n",
      "a [{0: 0}]\n",
      "reduced [{0: 0}]\n",
      "resolution [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "based [{0: 1}]\n",
      "on [{0: 1}]\n",
      "the [{0: 0}]\n",
      "input [{0: 0}]\n",
      "map [{0: 0}]\n",
      "; [{0: 1}]\n",
      "and [{0: 1}]\n",
      "\n",
      " [{0: 1}]\n",
      "at [{0: 0}]\n",
      "least [{0: 0}]\n",
      "one [{0: 0}]\n",
      "second [{0: 0}]\n",
      "processor [{0: 0}]\n",
      ", [{0: 1}]\n",
      "communicably [{0: 1}]\n",
      "connected [{0: 1}]\n",
      "to [{0: 1}]\n",
      "the [{0: 0}]\n",
      "at [{0: 0}]\n",
      "least [{0: 0}]\n",
      "one [{0: 0}]\n",
      "encrypted [{0: 0}]\n",
      "processor [{0: 0}]\n",
      ", [{0: 1}]\n",
      "that [{0: 1}]\n",
      "is [{0: 1}]\n",
      "configured [{0: 1}]\n",
      "to [{0: 1}]\n",
      ": [{0: 1}]\n",
      "\n",
      " [{0: 1}]\n",
      "receive [{0: 1}]\n",
      "the [{0: 0}]\n",
      "reduced [{0: 0}]\n",
      "resolution [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "and [{0: 1}]\n",
      "a [{0: 0}]\n",
      "plurality [{0: 0}]\n",
      "of [{0: 0}]\n",
      "similar [{0: 0}]\n",
      "patterns [{0: 0}]\n",
      ", [{0: 1}]\n",
      "each [{0: 1}]\n",
      "associated [{0: 1}]\n",
      "with [{0: 1}]\n",
      "a [{0: 0}]\n",
      "stored [{0: 0}]\n",
      "encrypted [{0: 0}]\n",
      "map [{0: 0}]\n",
      "template [{0: 0}]\n",
      ", [{0: 1}]\n",
      "and [{0: 1}]\n",
      "\n",
      " [{0: 1}]\n",
      "identify [{0: 1}]\n",
      "a [{0: 0}]\n",
      "match [{0: 0}]\n",
      "- [{0: 1}]\n",
      "set [{0: 1}]\n",
      "if [{0: 1}]\n",
      "a [{0: 0}]\n",
      "match [{0: 0}]\n",
      "exists [{0: 1}]\n",
      "between [{0: 1}]\n",
      "the [{0: 0}]\n",
      "reduced [{0: 0}]\n",
      "resolution [{0: 0}]\n",
      "pattern [{0: 0}]\n",
      "and [{0: 1}]\n",
      "the [{0: 0}]\n",
      "plurality [{0: 0}]\n",
      "of [{0: 0}]\n",
      "similar [{0: 0}]\n",
      "patterns [{0: 0}]\n",
      ", [{0: 1}]\n",
      "\n",
      "\n",
      " [{0: 1}]\n",
      "wherein [{0: 1}]\n",
      "the [{0: 0}]\n",
      "at [{0: 0}]\n",
      "least [{0: 0}]\n",
      "one [{0: 0}]\n",
      "encrypted [{0: 0}]\n",
      "processor [{0: 0}]\n",
      "is [{0: 1}]\n",
      "further [{0: 1}]\n",
      "configured [{0: 1}]\n",
      "to [{0: 1}]\n",
      "receive [{0: 1}]\n",
      "the [{0: 0}]\n",
      "match [{0: 0}]\n",
      "- [{0: 0}]\n",
      "set [{0: 0}]\n",
      "and [{0: 1}]\n",
      "identify [{0: 1}]\n",
      "if [{0: 1}]\n",
      "a [{0: 0}]\n",
      "match [{0: 0}]\n",
      "exists [{0: 1}]\n",
      "between [{0: 1}]\n",
      "the [{0: 0}]\n",
      "input [{0: 0}]\n",
      "map [{0: 0}]\n",
      "and [{0: 1}]\n",
      "any [{0: 0}]\n",
      "stored [{0: 0}]\n",
      "encrypted [{0: 0}]\n",
      "map [{0: 0}]\n",
      "template [{0: 0}]\n",
      "associated [{0: 1}]\n",
      "with [{0: 1}]\n",
      "the [{0: 0}]\n",
      "match [{0: 0}]\n",
      "- [{0: 0}]\n",
      "set [{0: 0}]\n",
      ". [{0: 1}]\n",
      "\n",
      "\n",
      " [{}]\n",
      "Extracted possible occurrences:\n",
      "\n",
      "[A device, at least one encrypted processor, an input map, a texture pattern, a reduced resolution pattern, the input map, at least one second processor, the at least one encrypted processor, the reduced resolution pattern, a plurality of similar patterns, a stored encrypted map template, a match, a match, the reduced resolution pattern, the plurality of similar patterns, the at least one encrypted processor, the match-set, a match, the input map, any stored encrypted map template, the match-set]\n",
      "\n",
      "1. A device, comprising:\n",
      "at least one encrypted processor that is configured to determine an input map associated with a texture pattern and calculate a reduced resolution pattern based on the input map; and\n",
      "at least one second processor, communicably connected to the at least one encrypted processor, that is configured to:\n",
      "receive the reduced resolution pattern and a plurality of similar patterns, each associated with a stored encrypted map template, and\n",
      "identify a match-set if a match exists between the reduced resolution pattern and the plurality of similar patterns,\n",
      "\n",
      "wherein the at least one encrypted processor is further configured to receive the match-set and identify if a match exists between the input map and any stored encrypted map template associated with the match-set.\n",
      "\n",
      "\n",
      "OrderedDict([('device', [A device]), ('at least one encrypted processor', [at least one encrypted processor, the at least one encrypted processor, the at least one encrypted processor]), ('input map', [an input map, the input map, the input map]), ('texture pattern', [a texture pattern]), ('reduced resolution pattern', [a reduced resolution pattern, the reduced resolution pattern, the reduced resolution pattern]), ('at least one second processor', [at least one second processor]), ('plurality of similar patterns', [a plurality of similar patterns, the plurality of similar patterns]), ('stored encrypted map template', [a stored encrypted map template, any stored encrypted map template]), ('match', [a match, a match, a match]), ('match-set', [the match-set, the match-set])])\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "# Try out with adding heuristics\n",
    "\n",
    "doc = nlp_docs[4]\n",
    "\n",
    "# Start with all words relate to no entities\n",
    "p_all_e_word = dict()\n",
    "\n",
    "# Initialise probabilities\n",
    "for token in doc:\n",
    "    p_all_e_word[token] = dict()\n",
    "\n",
    "# Is the order of our labelling important? Probably as we overwrite following probs    \n",
    "    \n",
    "# This can be combined with first pass easily - similar checks\n",
    "print(\"First pass - entity label heuristics\")\n",
    "for token in doc:\n",
    "    p_all_e_word = heuristics(token, doc, p_all_e_word)\n",
    "    print(token.text, \"[{0}]\".format(p_all_e_word[token]), end = '\\n')\n",
    "   \n",
    "print(\"Second pass - look for DET ... NOUN groupings\") \n",
    "# Third parse - take any DET ... NOUN <boundary> portions\n",
    "last_break = 0\n",
    "spans_to_match = list()\n",
    "for token in doc:\n",
    "    # Look for hard end points or DET\n",
    "    if (p_all_e_word[token].get(0, None) == 1) or (token.pos == DET):\n",
    "        print(\"{0} is e_0=1 or DET - looking back\".format(token))\n",
    "        # Step back marking as e_0=1 until first NOUN      \n",
    "        for j in range(token.i-1, last_break, -1):\n",
    "            print(\"Step back token - {0} with pos - {1}\".format(doc[j], doc[j].pos))\n",
    "            if doc[j].pos != NOUN:\n",
    "                print(\"Setting non-Noun\")\n",
    "                p_all_e_word[doc[j]][0] = 1\n",
    "            else:\n",
    "                last_break = j\n",
    "                break\n",
    "    # Look at grouping from DET\n",
    "    if is_det(token, doc):\n",
    "        # Tweak for \"at least X\" and \"X or more\"\n",
    "        if (\n",
    "            doc[token.i:token.i + 2].text.lower() == \"at least\" and doc[token.i + 2].pos == NUM\n",
    "        ) or (\n",
    "            doc[token.i+1:token.i + 3].text.lower() == \"or more\" and token.pos == NUM\n",
    "        ):\n",
    "            #print(\"Head index set to {0}\".format())\n",
    "            head_index = doc[token.i+2].head.i\n",
    "        else: \n",
    "            head_index = token.head.i\n",
    "        possible_entity = True\n",
    "        # Step through intermediate tokens between current and head\n",
    "        for j in range(token.i, head_index):\n",
    "            # If head is outside of DET ... end_NOUN sequence\n",
    "            if doc[j].head.i < token.i and doc[j].head.i > head_index:\n",
    "                # Check for nested portions\n",
    "                possible_entity = False\n",
    "        if possible_entity:\n",
    "            for k in range(token.i, head_index + 1):\n",
    "                p_all_e_word[doc[k]][0] = 0 \n",
    "  # Need to adapt the above for at least one ... X and one or more ... Xs - \"at\" > head > \"least\" > \"one\" > X              \n",
    "    \n",
    "for token in doc:\n",
    "    print(token.text, \"[{0}]\".format(p_all_e_word[token]), end = '\\n') \n",
    "\n",
    "print(\"Extracted possible occurrences:\\n\")\n",
    "poss_occ = list()\n",
    "for token in doc[1:]:\n",
    "    # If transition\n",
    "    if p_all_e_word[token].get(0, 1) == 0 and p_all_e_word[doc[token.i-1]].get(0, 0) == 1:\n",
    "        # Add consecutive e_0=0\n",
    "        for j in range(token.i, len(doc)+1):\n",
    "            if p_all_e_word[doc[j]].get(0, 1) != 0:\n",
    "                poss_occ.append(doc[token.i:j])\n",
    "                break\n",
    "\n",
    "print(poss_occ)\n",
    "\n",
    "# Matching occurrences\n",
    "entity_dict = dict()\n",
    "# Now group by unique\n",
    "for entity in poss_occ:\n",
    "    np_start = entity.start\n",
    "    # Ignore the determinant \n",
    "    if doc[np_start].pos == DET:\n",
    "        np_start += 1\n",
    "    # Generate a string representation excluding the determinant\n",
    "    np_string = doc[np_start:entity.end].text.lower()                        \n",
    "    if np_string not in entity_dict.keys():\n",
    "        entity_dict[np_string] = list()          \n",
    "    entity_dict[np_string].append(entity)\n",
    "\n",
    "print(doc)\n",
    "# print(entity_dict)\n",
    "\n",
    "# Quick function to sort entities by occurrence\n",
    "# Need to sort the keys by the index of the first word in the first entry\n",
    "ordered_entities = OrderedDict(sorted(entity_dict.items(), key=lambda t: t[1][0][0].i))\n",
    "\n",
    "print(ordered_entities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper - http://cogprints.org/5025/1/nrc-48727.pdf - suggests a two-phase process:\n",
    "* Generate a \"gazetteer\" (a list of named entities) - similar to our first stage of simple_entity_extraction method;\n",
    "* Disambiguate names in \"gazetteer\" (this is similar to our second stage of simple_entity_extraction method)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Look for spans between e_0=1 - these must contain an occurrence. If there is only one DET-NOUN (check NP using head) or X NNS (check again using NP head) - that must be an entity. (This is the second parse?)\n",
    "\n",
    "Can we look backwards from DET? Anything that is not a NOUN is e_0=1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the algorithm generally:\n",
    "* Mark as entity or not based on rules;\n",
    "* Look back from DET or punct break [':',';',',','.'] - set as non-entity until noun is found;\n",
    "* Look at noun phrase chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at plural nouns\n",
    "if token.tag_ == \"NNS\":\n",
    "    #Step back and mark as e_0=0 any preceding word that has the token as a head\n",
    "    for j in range(token.i, 0, -1):\n",
    "        if (doc[j].head.i == (doc[j].i-1)) and p_all_e_word[doc[j-1]].get(0,0) != 1:\n",
    "            p_all_e_word[doc[j-1]][0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 \n",
      " SPACE 1 1 SP\n",
      "1 1 1 PUNCT 1 1 LS\n",
      ". 2 . PUNCT 1 1 .\n",
      "A 3 a DET device 4 DT\n",
      "device 4 device NOUN identify 86 NN\n",
      ", 5 , PUNCT device 4 ,\n",
      "comprising 6 comprise VERB device 4 VBG\n",
      ": 7 : PUNCT comprising 6 :\n",
      "\n",
      " 8 \n",
      " SPACE : 7 SP\n",
      "at 9 at ADP least 10 IN\n",
      "least 10 least ADJ one 11 JJS\n",
      "one 11 one NUM processor 13 CD\n",
      "encrypted 12 encrypt VERB processor 13 VBN\n",
      "processor 13 processor NOUN comprising 6 NN\n",
      "that 14 that ADJ configured 16 WDT\n",
      "is 15 be VERB configured 16 VBZ\n",
      "configured 16 configure VERB processor 13 VBN\n",
      "to 17 to PART determine 18 TO\n",
      "determine 18 determine VERB configured 16 VB\n",
      "an 19 an DET map 21 DT\n",
      "input 20 input NOUN map 21 NN\n",
      "map 21 map NOUN determine 18 NN\n",
      "associated 22 associate VERB map 21 VBN\n",
      "with 23 with ADP associated 22 IN\n",
      "a 24 a DET pattern 26 DT\n",
      "texture 25 texture NOUN pattern 26 NN\n",
      "pattern 26 pattern NOUN with 23 NN\n",
      "and 27 and CCONJ determine 18 CC\n",
      "calculate 28 calculate VERB determine 18 VB\n",
      "a 29 a DET pattern 32 DT\n",
      "reduced 30 reduced ADJ pattern 32 JJ\n",
      "resolution 31 resolution NOUN pattern 32 NN\n",
      "pattern 32 pattern NOUN calculate 28 NN\n",
      "based 33 base VERB pattern 32 VBN\n",
      "on 34 on ADP based 33 IN\n",
      "the 35 the DET map 37 DT\n",
      "input 36 input NOUN map 37 NN\n",
      "map 37 map NOUN on 34 NN\n",
      "; 38 ; PUNCT pattern 32 :\n",
      "and 39 and CCONJ pattern 32 CC\n",
      "\n",
      " 40 \n",
      " SPACE and 39 SP\n",
      "at 41 at ADV least 42 RB\n",
      "least 42 least ADV one 43 RBS\n",
      "one 43 one NUM processor 45 CD\n",
      "second 44 second ADJ processor 45 JJ\n",
      "processor 45 processor NOUN pattern 32 NN\n",
      ", 46 , PUNCT processor 45 ,\n",
      "communicably 47 communicably ADV connected 48 RB\n",
      "connected 48 connect VERB processor 45 VBN\n",
      "to 49 to ADP connected 48 IN\n",
      "the 50 the DET processor 55 DT\n",
      "at 51 at ADV least 52 RB\n",
      "least 52 least ADJ one 53 JJS\n",
      "one 53 one NUM processor 55 CD\n",
      "encrypted 54 encrypt VERB processor 55 VBN\n",
      "processor 55 processor NOUN to 49 NN\n",
      ", 56 , PUNCT processor 55 ,\n",
      "that 57 that DET configured 59 DT\n",
      "is 58 be VERB configured 59 VBZ\n",
      "configured 59 configure VERB processor 55 VBN\n",
      "to 60 to ADP configured 59 IN\n",
      ": 61 : PUNCT processor 55 :\n",
      "\n",
      " 62 \n",
      " SPACE : 61 SP\n",
      "receive 63 receive VERB processor 55 VB\n",
      "the 64 the DET pattern 67 DT\n",
      "reduced 65 reduced ADJ pattern 67 JJ\n",
      "resolution 66 resolution NOUN pattern 67 NN\n",
      "pattern 67 pattern NOUN receive 63 NN\n",
      "and 68 and CCONJ pattern 67 CC\n",
      "a 69 a DET plurality 70 DT\n",
      "plurality 70 plurality NOUN pattern 67 NN\n",
      "of 71 of ADP plurality 70 IN\n",
      "similar 72 similar ADJ patterns 73 JJ\n",
      "patterns 73 pattern NOUN of 71 NNS\n",
      ", 74 , PUNCT patterns 73 ,\n",
      "each 75 each DET associated 76 DT\n",
      "associated 76 associate VERB pattern 67 VBN\n",
      "with 77 with ADP associated 76 IN\n",
      "a 78 a DET template 82 DT\n",
      "stored 79 store VERB template 82 VBN\n",
      "encrypted 80 encrypt VERB template 82 VBN\n",
      "map 81 map NOUN template 82 NN\n",
      "template 82 template NOUN with 77 NN\n",
      ", 83 , PUNCT template 82 ,\n",
      "and 84 and CCONJ template 82 CC\n",
      "\n",
      " 85 \n",
      " SPACE and 84 SP\n",
      "identify 86 identify VERB identify 86 VB\n",
      "a 87 a DET set 90 DT\n",
      "match 88 match NOUN set 90 NN\n",
      "- 89 - PUNCT set 90 HYPH\n",
      "set 90 set VERB identify 86 VBN\n",
      "if 91 if ADP exists 94 IN\n",
      "a 92 a DET match 93 DT\n",
      "match 93 match NOUN exists 94 NN\n",
      "exists 94 exist VERB set 90 VBZ\n",
      "between 95 between ADP exists 94 IN\n",
      "the 96 the DET pattern 99 DT\n",
      "reduced 97 reduced ADJ pattern 99 JJ\n",
      "resolution 98 resolution NOUN pattern 99 NN\n",
      "pattern 99 pattern NOUN between 95 NN\n",
      "and 100 and CCONJ pattern 99 CC\n",
      "the 101 the DET plurality 102 DT\n",
      "plurality 102 plurality NOUN pattern 99 NN\n",
      "of 103 of ADP plurality 102 IN\n",
      "similar 104 similar ADJ patterns 105 JJ\n",
      "patterns 105 pattern NOUN of 103 NNS\n",
      ", 106 , PUNCT patterns 105 ,\n",
      "\n",
      "\n",
      " 107 \n",
      "\n",
      " SPACE , 106 SP\n",
      "wherein 108 wherein ADV plurality 102 WRB\n",
      "the 109 the DET processor 114 DT\n",
      "at 110 at ADV least 111 RB\n",
      "least 111 least ADJ one 112 JJS\n",
      "one 112 one NUM processor 114 CD\n",
      "encrypted 113 encrypt VERB processor 114 VBN\n",
      "processor 114 processor NOUN wherein 108 NN\n",
      "is 115 be VERB configured 117 VBZ\n",
      "further 116 further ADV configured 117 RBR\n",
      "configured 117 configure VERB processor 114 VBN\n",
      "to 118 to PART receive 119 TO\n",
      "receive 119 receive VERB configured 117 VB\n",
      "the 120 the DET set 123 DT\n",
      "match 121 match NOUN set 123 NN\n",
      "- 122 - PUNCT set 123 HYPH\n",
      "set 123 set NOUN receive 119 NN\n",
      "and 124 and CCONJ receive 119 CC\n",
      "identify 125 identify VERB receive 119 VB\n",
      "if 126 if ADP exists 129 IN\n",
      "a 127 a DET match 128 DT\n",
      "match 128 match NOUN exists 129 NN\n",
      "exists 129 exist VERB identify 125 VBZ\n",
      "between 130 between ADP exists 129 IN\n",
      "the 131 the DET map 133 DT\n",
      "input 132 input NOUN map 133 NN\n",
      "map 133 map NOUN between 130 NN\n",
      "and 134 and CCONJ map 133 CC\n",
      "any 135 any DET template 139 DT\n",
      "stored 136 store VERB template 139 VBN\n",
      "encrypted 137 encrypt VERB template 139 VBN\n",
      "map 138 map NOUN template 139 NN\n",
      "template 139 template NOUN map 133 NN\n",
      "associated 140 associate VERB template 139 VBN\n",
      "with 141 with ADP associated 140 IN\n",
      "the 142 the DET set 145 DT\n",
      "match 143 match NOUN set 145 NN\n",
      "- 144 - PUNCT set 145 HYPH\n",
      "set 145 set NOUN with 141 NN\n",
      ". 146 . PUNCT identify 86 .\n",
      "\n",
      "\n",
      " 147 \n",
      "\n",
      " SPACE . 146 SP\n"
     ]
    }
   ],
   "source": [
    "# Look at POS and head for each token\n",
    "doc = nlp_docs[4]\n",
    "for token in doc:\n",
    "    print(token.text, token.i, token.lemma_, token.pos_, token.head.text, token.head.i, token.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we look for each DET then label as entity until head noun if head = head noun?  \n",
    "\n",
    "If we have a span between an e_0=0 and a noun - label as an entity occurrence if all tokens in span have the same head.\n",
    "\n",
    "We can get plurals by looking for plural nouns then tracing back to find previous tokens with the plural noun as head.\n",
    "\n",
    "Patterns like this:\n",
    "```\n",
    "a 21 a DET unit 25\n",
    "vehicle 22 vehicle NOUN side 24\n",
    "- 23 - PUNCT side 24\n",
    "side 24 side NOUN unit 25\n",
    "unit 25 unit NOUN mounted 26\n",
    "```\n",
    "Can be resolved - vehicle-side is a subtree where the head of side still points to unit. So the head doesn't need to point to the end noun but it does need.\n",
    "\n",
    "All our sub-phrases need to be between DET and head noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_head(token, doc, end_head):\n",
    "    \"\"\" Check for noun phrase .\"\"\"\n",
    "    if token.head != end_head and token.head.i > token.i:\n",
    "        check_head(token.head, doc, end_head)\n",
    "    else:\n",
    "        if \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n",
      "1.'\n",
      "\n",
      " False\n",
      "'1. a'\n",
      "1 False\n",
      "'. a device'\n",
      ". False\n",
      "'a device,'\n",
      "A False\n",
      "'device, comprising'\n",
      "device False\n",
      "', comprising:'\n",
      ", False\n",
      "'comprising:\n",
      "'\n",
      "comprising False\n",
      "':\n",
      "at'\n",
      ": False\n",
      "'\n",
      "at least'\n",
      "\n",
      " False\n",
      "'at least one'\n",
      "at True\n",
      "'least one encrypted'\n",
      "least False\n",
      "'one encrypted processor'\n",
      "one False\n",
      "'encrypted processor that'\n",
      "encrypted False\n",
      "'processor that is'\n",
      "processor False\n",
      "'that is configured'\n",
      "that False\n",
      "'is configured to'\n",
      "is False\n",
      "'configured to determine'\n",
      "configured False\n",
      "'to determine an'\n",
      "to False\n",
      "'determine an input'\n",
      "determine False\n",
      "'an input map'\n",
      "an False\n",
      "'input map associated'\n",
      "input False\n",
      "'map associated with'\n",
      "map False\n",
      "'associated with a'\n",
      "associated False\n",
      "'with a texture'\n",
      "with False\n",
      "'a texture pattern'\n",
      "a False\n",
      "'texture pattern and'\n",
      "texture False\n",
      "'pattern and calculate'\n",
      "pattern False\n",
      "'and calculate a'\n",
      "and False\n",
      "'calculate a reduced'\n",
      "calculate False\n",
      "'a reduced resolution'\n",
      "a False\n",
      "'reduced resolution pattern'\n",
      "reduced False\n",
      "'resolution pattern based'\n",
      "resolution False\n",
      "'pattern based on'\n",
      "pattern False\n",
      "'based on the'\n",
      "based False\n",
      "'on the input'\n",
      "on False\n",
      "'the input map'\n",
      "the False\n",
      "'input map;'\n",
      "input False\n",
      "'map; and'\n",
      "map False\n",
      "'; and\n",
      "'\n",
      "; False\n",
      "'and\n",
      "at'\n",
      "and False\n",
      "'\n",
      "at least'\n",
      "\n",
      " False\n",
      "'at least one'\n",
      "at True\n",
      "'least one second'\n",
      "least False\n",
      "'one second processor'\n",
      "one False\n",
      "'second processor,'\n",
      "second False\n",
      "'processor, communicably'\n",
      "processor False\n",
      "', communicably connected'\n",
      ", False\n",
      "'communicably connected to'\n",
      "communicably False\n",
      "'connected to the'\n",
      "connected False\n",
      "'to the at'\n",
      "to False\n",
      "'the at least'\n",
      "the False\n",
      "'at least one'\n",
      "at True\n",
      "'least one encrypted'\n",
      "least False\n",
      "'one encrypted processor'\n",
      "one False\n",
      "'encrypted processor,'\n",
      "encrypted False\n",
      "'processor, that'\n",
      "processor False\n",
      "', that is'\n",
      ", False\n",
      "'that is configured'\n",
      "that False\n",
      "'is configured to'\n",
      "is False\n",
      "'configured to:'\n",
      "configured False\n",
      "'to:\n",
      "'\n",
      "to False\n",
      "':\n",
      "receive'\n",
      ": False\n",
      "'\n",
      "receive the'\n",
      "\n",
      " False\n",
      "'receive the reduced'\n",
      "receive False\n",
      "'the reduced resolution'\n",
      "the False\n",
      "'reduced resolution pattern'\n",
      "reduced False\n",
      "'resolution pattern and'\n",
      "resolution False\n",
      "'pattern and a'\n",
      "pattern False\n",
      "'and a plurality'\n",
      "and False\n",
      "'a plurality of'\n",
      "a False\n",
      "'plurality of similar'\n",
      "plurality False\n",
      "'of similar patterns'\n",
      "of False\n",
      "'similar patterns,'\n",
      "similar False\n",
      "'patterns, each'\n",
      "patterns False\n",
      "', each associated'\n",
      ", False\n",
      "'each associated with'\n",
      "each False\n",
      "'associated with a'\n",
      "associated False\n",
      "'with a stored'\n",
      "with False\n",
      "'a stored encrypted'\n",
      "a False\n",
      "'stored encrypted map'\n",
      "stored False\n",
      "'encrypted map template'\n",
      "encrypted False\n",
      "'map template,'\n",
      "map False\n",
      "'template, and'\n",
      "template False\n",
      "', and\n",
      "'\n",
      ", False\n",
      "'and\n",
      "identify'\n",
      "and False\n",
      "'\n",
      "identify a'\n",
      "\n",
      " False\n",
      "'identify a match'\n",
      "identify False\n",
      "'a match-'\n",
      "a False\n",
      "'match-set'\n",
      "match False\n",
      "'-set if'\n",
      "- False\n",
      "'set if a'\n",
      "set False\n",
      "'if a match'\n",
      "if False\n",
      "'a match exists'\n",
      "a False\n",
      "'match exists between'\n",
      "match False\n",
      "'exists between the'\n",
      "exists False\n",
      "'between the reduced'\n",
      "between False\n",
      "'the reduced resolution'\n",
      "the False\n",
      "'reduced resolution pattern'\n",
      "reduced False\n",
      "'resolution pattern and'\n",
      "resolution False\n",
      "'pattern and the'\n",
      "pattern False\n",
      "'and the plurality'\n",
      "and False\n",
      "'the plurality of'\n",
      "the False\n",
      "'plurality of similar'\n",
      "plurality False\n",
      "'of similar patterns'\n",
      "of False\n",
      "'similar patterns,'\n",
      "similar False\n",
      "'patterns,\n",
      "\n",
      "'\n",
      "patterns False\n",
      "',\n",
      "\n",
      "wherein'\n",
      ", False\n",
      "'\n",
      "\n",
      "wherein the'\n",
      "\n",
      "\n",
      " False\n",
      "'wherein the at'\n",
      "wherein False\n",
      "'the at least'\n",
      "the False\n",
      "'at least one'\n",
      "at True\n",
      "'least one encrypted'\n",
      "least False\n",
      "'one encrypted processor'\n",
      "one False\n",
      "'encrypted processor is'\n",
      "encrypted False\n",
      "'processor is further'\n",
      "processor False\n",
      "'is further configured'\n",
      "is False\n",
      "'further configured to'\n",
      "further False\n",
      "'configured to receive'\n",
      "configured False\n",
      "'to receive the'\n",
      "to False\n",
      "'receive the match'\n",
      "receive False\n",
      "'the match-'\n",
      "the False\n",
      "'match-set'\n",
      "match False\n",
      "'-set and'\n",
      "- False\n",
      "'set and identify'\n",
      "set False\n",
      "'and identify if'\n",
      "and False\n",
      "'identify if a'\n",
      "identify False\n",
      "'if a match'\n",
      "if False\n",
      "'a match exists'\n",
      "a False\n",
      "'match exists between'\n",
      "match False\n",
      "'exists between the'\n",
      "exists False\n",
      "'between the input'\n",
      "between False\n",
      "'the input map'\n",
      "the False\n",
      "'input map and'\n",
      "input False\n",
      "'map and any'\n",
      "map False\n",
      "'and any stored'\n",
      "and False\n",
      "'any stored encrypted'\n",
      "any False\n",
      "'stored encrypted map'\n",
      "stored False\n",
      "'encrypted map template'\n",
      "encrypted False\n",
      "'map template associated'\n",
      "map False\n",
      "'template associated with'\n",
      "template False\n",
      "'associated with the'\n",
      "associated False\n",
      "'with the match'\n",
      "with False\n",
      "'the match-'\n",
      "the False\n",
      "'match-set'\n",
      "match False\n",
      "'-set.'\n",
      "- False\n",
      "'set.\n",
      "\n",
      "'\n",
      "set False\n",
      "'.\n",
      "\n",
      "'\n",
      ". False\n",
      "'\n",
      "\n",
      "'\n",
      "\n",
      "\n",
      " False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    i = token.i\n",
    "    print(\"'{0}'\".format(doc[i:i+3].text.lower()))\n",
    "    condition = (\n",
    "        doc[i:i+3].text.lower() == \"at least one\" or\n",
    "        doc[i:i+3].text.lower() == \"one or more\"\n",
    "    )\n",
    "    print(token, condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When matching what to do with 'the time scale' and 'the time scale display information' or 'a project' and:\n",
    "```\n",
    "A [{0: 0}]\n",
    "project [{}]\n",
    "information [{0: 0}]\n",
    "display [{0: 0}]\n",
    "device [{0: 0}]\n",
    ", [{0: 1}]\n",
    "comprising [{}]\n",
    ": [{0: 1}]\n",
    "```\n",
    "Only look for e_0 stretches of same number with matching pos and text? (Are we now getting to look at transitions?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are issues with \"(a)\" and \"a.\"\n",
    "\n",
    "Also \"response\" from \"in response\".\n",
    "\n",
    "Check det is not working for \"at least one\"\n",
    "\n",
    "We can iterate back from where e_0 = 1 - tokens between a last noun and determinant will be part of an entity. We can then match those across the claim. This is the simple entity finder but stepping back at [:;,.] as well as DET.  \n",
    "Pattern is:\n",
    "* If next step back is e_0=0;\n",
    "* If next e_0=0 is a check_det=True;\n",
    "* Fill in inbetween as e_0=0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accordance': [accordance],\n",
       " 'associated user': [an associated user],\n",
       " 'communication device': [a communication device,\n",
       "  the communication device,\n",
       "  the communication device],\n",
       " 'content filter engine': [a content filter engine],\n",
       " 'data': [data],\n",
       " 'information': [information],\n",
       " 'personal content filter database': [a personal content filter database],\n",
       " 'predefined rules': [predefined rules,\n",
       "  predefined rules,\n",
       "  predefined rules,\n",
       "  predefined rules],\n",
       " 'rules': [rules],\n",
       " 'server': [a server],\n",
       " 'set': [a set, the set, the set, the set],\n",
       " 'system': [A system],\n",
       " 'user': [user],\n",
       " 'user interface': [a user interface]}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_entity_finder(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'associated user': [an associated user],\n",
       " 'communication device': [the communication device],\n",
       " 'communication device in accordance': [a communication device in accordance],\n",
       " 'content filter engine': [a content filter engine],\n",
       " 'personal content filter database': [a personal content filter database],\n",
       " 'server': [a server],\n",
       " 'set of predefined rules': [a set of predefined rules,\n",
       "  the set of predefined rules],\n",
       " 'set of predefined rules by preventing restricted information': [the set of predefined rules by preventing restricted information],\n",
       " 'set of predefined rules comprising user defined rules': [the set of predefined rules comprising user defined rules],\n",
       " 'system': [the system],\n",
       " 'system for filtering data': [A system for filtering data],\n",
       " 'user interface': [a user interface]}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_spacy_entity_finder(doc)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another pattern is \"DET X FOR [phrase]\" - this is one entity? But contains references to other entities\n",
    "```\n",
    "a [{0: 0}]\n",
    "system [{0: 0}]\n",
    "for [{}]\n",
    "providing [{}]\n",
    "a [{0: 0}]\n",
    "plurality [{0: 0}]\n",
    "of [{}]\n",
    "football [{0: 0}]\n",
    "player [{0: 0}]\n",
    "types [{0: 0}]\n",
    "from [{}]\n",
    "which [{}]\n",
    "a [{0: 0}]\n",
    "football [{0: 0}]\n",
    "player [{0: 0}]\n",
    "type [{0: 0}]\n",
    "is [{}]\n",
    "selected \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a for clause as the whole entity string - e.g. \"A method for modeling electrical characteristics of cells having given circuit elements\" and \"a layout of cells having at least one cell\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
